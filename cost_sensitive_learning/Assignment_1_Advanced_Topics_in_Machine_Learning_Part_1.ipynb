{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panagiotismouts/machinelearning/blob/main/cost_sensitive_learning/Assignment_1_Advanced_Topics_in_Machine_Learning_Part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 1 - Part 1\n",
        "\n",
        "\n",
        "\n",
        "Andreas Kiziridis - Erasmus Student\n",
        "\n",
        "Moutsiounas Panagiotis - 153\n"
      ],
      "metadata": {
        "id": "HNPSMLhtpf-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this task, we will be using one technic of sampling, weighting and of expected cost minimization. First, we  will train the dataset in the three different algorithms, providing a cost matrix for each to calculate the metrics without applying any techniques. "
      ],
      "metadata": {
        "id": "aPImyZ6PrGkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from collections import Counter\n",
        "from sklearn.datasets import  fetch_openml\n",
        "from sklearn.compose import make_column_transformer, make_column_selector\n",
        "\n",
        "X, y = fetch_openml(\"credit-g\", version=1, as_frame=True, parser='auto', return_X_y=True)\n",
        "\n",
        "data_names = X.columns\n",
        "\n",
        "one_hot_encoder = make_column_transformer(\n",
        "    (OneHotEncoder(sparse_output=False, handle_unknown='ignore'),\n",
        "     make_column_selector(dtype_include='category')),\n",
        "    remainder='passthrough')\n",
        "\n",
        "X = one_hot_encoder.fit_transform(X)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "print(Counter(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTiaa9FE2RTF",
        "outputId": "41058f9c-572e-4130-f633-251b7d157b2a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'good': 700, 'bad': 300})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# create a cost-matrix as in slides\n",
        "cost_m = [[0, 1], \n",
        "          [5, 0]]\n",
        "\n",
        "#training the data\n",
        "names = ['random forest', 'linear SVM', 'gaussian naïve bayes']\n",
        "\n",
        "classifiers = [RandomForestClassifier(n_estimators=150, random_state=42), \n",
        "               SVC(kernel='linear'), GaussianNB()]\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "  print(\" \")\n",
        "  print(name)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(classification_report(y_test, y_pred, target_names=['bad', 'good']))\n",
        "  conf_m = confusion_matrix(y_test, y_pred).T # transpose to align with slides\n",
        "  print(conf_m) \n",
        "  print(\"total cost: \", np.sum(conf_m * cost_m))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R1oWO2UtpUoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d727f256-a9d2-48e1-b559-4743962de773"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "random forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.69      0.37      0.49        91\n",
            "         bad       0.77      0.93      0.84       209\n",
            "\n",
            "    accuracy                           0.76       300\n",
            "   macro avg       0.73      0.65      0.66       300\n",
            "weighted avg       0.75      0.76      0.73       300\n",
            "\n",
            "[[ 34  15]\n",
            " [ 57 194]]\n",
            "total cost:  300\n",
            " \n",
            "linear SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.66      0.48      0.56        91\n",
            "         bad       0.80      0.89      0.84       209\n",
            "\n",
            "    accuracy                           0.77       300\n",
            "   macro avg       0.73      0.69      0.70       300\n",
            "weighted avg       0.76      0.77      0.76       300\n",
            "\n",
            "[[ 44  23]\n",
            " [ 47 186]]\n",
            "total cost:  258\n",
            " \n",
            "gaussian naïve bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.51      0.74      0.60        91\n",
            "         bad       0.86      0.69      0.76       209\n",
            "\n",
            "    accuracy                           0.70       300\n",
            "   macro avg       0.68      0.71      0.68       300\n",
            "weighted avg       0.75      0.70      0.71       300\n",
            "\n",
            "[[ 67  65]\n",
            " [ 24 144]]\n",
            "total cost:  185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the first technic, we will use a cost-based sampling technic. Because our dataset is small, we decided to use oversampling. If we would want to save computation time, perhaps we could use undersampling.\n",
        "\n"
      ],
      "metadata": {
        "id": "86_-pG5X7nO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "print(\"Counter before oversampling: \",Counter(y_train))\n",
        "#from the counter occurs:\n",
        "#'good': 491, 'bad': 209\n",
        "#so we decided oversample the data with \"bad\" on the target value, because the cost is higher (5x)\n",
        "#and most classes have \"good\" as their target value.\n",
        "\n",
        "#training the data\n",
        "sampler = RandomOverSampler(sampling_strategy={'good':491 , 'bad': 491}, random_state=42) \n",
        "X_rs, y_rs = sampler.fit_resample(X_train, y_train)\n",
        "print(\"Counter after oversampling:\",Counter(y_rs))\n",
        "\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "  print(\" \")\n",
        "  print(name)\n",
        "  clf.fit(X_rs, y_rs)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(classification_report(y_test, y_pred, target_names=['bad', 'good']))\n",
        "  conf_m = confusion_matrix(y_test, y_pred).T # transpose to align with slides\n",
        "  print(conf_m) \n",
        "  print(\"total cost: \", np.sum(conf_m * cost_m))\n",
        "\n",
        "#training the data\n",
        "sampler = RandomUnderSampler(sampling_strategy={'good':209 , 'bad': 209}, random_state=42) \n",
        "X_rs, y_rs = sampler.fit_resample(X_train, y_train)\n",
        "print(\"Counter after undersampling:\",Counter(y_rs))\n",
        "\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "  print(\" \")\n",
        "  print(name)\n",
        "  clf.fit(X_rs, y_rs)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(classification_report(y_test, y_pred, target_names=['bad', 'good']))\n",
        "  conf_m = confusion_matrix(y_test, y_pred).T # transpose to align with slides\n",
        "  print(conf_m) \n",
        "  print(\"total cost: \", np.sum(conf_m * cost_m))\n",
        "\n",
        "\n",
        "# By applying the sampling techniques we could minimize our costs significantly.\n",
        "# We noticed that undersampling combined with Random Forest and Linear SVM produced the best results (cost of 180 and 195).\n",
        "# For Naive Bayes the cost could be reduced to 180/181 by over and undersampling."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5wiLIbSpv_v",
        "outputId": "e6532551-8fcd-4a90-bbf3-76fca9ed937c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter before oversampling:  Counter({'good': 491, 'bad': 209})\n",
            "Counter after oversampling: Counter({'good': 491, 'bad': 491})\n",
            " \n",
            "random forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.60      0.48      0.54        91\n",
            "         bad       0.79      0.86      0.83       209\n",
            "\n",
            "    accuracy                           0.75       300\n",
            "   macro avg       0.70      0.67      0.68       300\n",
            "weighted avg       0.74      0.75      0.74       300\n",
            "\n",
            "[[ 44  29]\n",
            " [ 47 180]]\n",
            "total cost:  264\n",
            " \n",
            "linear SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.50      0.67      0.58        91\n",
            "         bad       0.83      0.71      0.77       209\n",
            "\n",
            "    accuracy                           0.70       300\n",
            "   macro avg       0.67      0.69      0.67       300\n",
            "weighted avg       0.73      0.70      0.71       300\n",
            "\n",
            "[[ 61  60]\n",
            " [ 30 149]]\n",
            "total cost:  210\n",
            " \n",
            "gaussian naïve bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.48      0.77      0.59        91\n",
            "         bad       0.86      0.64      0.74       209\n",
            "\n",
            "    accuracy                           0.68       300\n",
            "   macro avg       0.67      0.71      0.66       300\n",
            "weighted avg       0.75      0.68      0.69       300\n",
            "\n",
            "[[ 70  75]\n",
            " [ 21 134]]\n",
            "total cost:  180\n",
            "Counter after undersampling: Counter({'bad': 209, 'good': 209})\n",
            " \n",
            "random forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.51      0.74      0.60        91\n",
            "         bad       0.86      0.69      0.76       209\n",
            "\n",
            "    accuracy                           0.70       300\n",
            "   macro avg       0.68      0.71      0.68       300\n",
            "weighted avg       0.75      0.70      0.71       300\n",
            "\n",
            "[[ 67  65]\n",
            " [ 24 144]]\n",
            "total cost:  185\n",
            " \n",
            "linear SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.52      0.69      0.59        91\n",
            "         bad       0.84      0.72      0.78       209\n",
            "\n",
            "    accuracy                           0.71       300\n",
            "   macro avg       0.68      0.71      0.69       300\n",
            "weighted avg       0.75      0.71      0.72       300\n",
            "\n",
            "[[ 63  58]\n",
            " [ 28 151]]\n",
            "total cost:  198\n",
            " \n",
            "gaussian naïve bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.49      0.76      0.60        91\n",
            "         bad       0.86      0.66      0.75       209\n",
            "\n",
            "    accuracy                           0.69       300\n",
            "   macro avg       0.68      0.71      0.67       300\n",
            "weighted avg       0.75      0.69      0.70       300\n",
            "\n",
            "[[ 69  71]\n",
            " [ 22 138]]\n",
            "total cost:  181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After using oversampling and undersampling and recording the differences in the cost, we will proceed with weighting."
      ],
      "metadata": {
        "id": "u4ceBJ8SILb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "weights = np.zeros(y_train.shape[0])\n",
        "weights[np.where(y_train == 'good')] = 1;\n",
        "weights[np.where(y_train == 'bad')] = 5;\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "  print(\" \")\n",
        "  print(name)\n",
        "  clf.fit(X_train, y_train, weights)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(classification_report(y_test, y_pred, target_names=['bad', 'good']))\n",
        "  conf_m = confusion_matrix(y_test, y_pred).T # transpose to align with slides\n",
        "  print(conf_m) \n",
        "  print(\"total cost: \", np.sum(conf_m * cost_m))\n",
        "\n",
        "#after using weights accordingly with the cost matrix, we can conclude that:\n",
        "#the random forest gets worse results. (300 - 337)\n",
        "#the linear svm gets significantly better (258 - 135)\n",
        "#the gaussian naïve bayes also gets better (185 - 164)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-3ql8KLIKLF",
        "outputId": "aad9a80d-677d-478b-eb13-1c0db28589f3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "random forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.68      0.29      0.40        91\n",
            "         bad       0.75      0.94      0.84       209\n",
            "\n",
            "    accuracy                           0.74       300\n",
            "   macro avg       0.72      0.61      0.62       300\n",
            "weighted avg       0.73      0.74      0.71       300\n",
            "\n",
            "[[ 26  12]\n",
            " [ 65 197]]\n",
            "total cost:  337\n",
            " \n",
            "linear SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.46      0.92      0.61        91\n",
            "         bad       0.94      0.52      0.67       209\n",
            "\n",
            "    accuracy                           0.64       300\n",
            "   macro avg       0.70      0.72      0.64       300\n",
            "weighted avg       0.79      0.64      0.65       300\n",
            "\n",
            "[[ 84 100]\n",
            " [  7 109]]\n",
            "total cost:  135\n",
            " \n",
            "gaussian naïve bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        good       0.47      0.82      0.60        91\n",
            "         bad       0.89      0.60      0.71       209\n",
            "\n",
            "    accuracy                           0.67       300\n",
            "   macro avg       0.68      0.71      0.66       300\n",
            "weighted avg       0.76      0.67      0.68       300\n",
            "\n",
            "[[ 75  84]\n",
            " [ 16 125]]\n",
            "total cost:  164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimizing expected cost"
      ],
      "metadata": {
        "id": "KKhv5974PZrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#first we will minimize it without probability calibration\n",
        "#we need to have numerical values in our target column to perform the matrix multiplication\n",
        "#and calculate the probabilities.\n",
        "\n",
        "label_map = {\"good\": 0, \"bad\": 1}\n",
        "\n",
        "y_train_num = [label_map[c] for c in y_train]\n",
        "y_test_num = [label_map[c] for c in y_test]\n",
        "\n",
        "classifiers = [RandomForestClassifier(n_estimators=150, random_state=42), \n",
        "               SVC(kernel='linear', probability=True), GaussianNB()]\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "  print(\" \")\n",
        "  print(name)\n",
        "  model = clf.fit(X_train, y_train_num)\n",
        "\n",
        "  y_pred_prob = model.predict_proba(X_test)\n",
        "\n",
        "  y_pred = np.argmin(np.matmul(y_pred_prob, np.array(cost_m).T), axis=1) \n",
        "  print(classification_report(y_test_num, y_pred, target_names=['bad', 'good']))\n",
        "  conf_m = confusion_matrix(y_test_num, y_pred).T\n",
        "  print(conf_m) \n",
        "  print(\"total cost: \", np.sum(conf_m * cost_m))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ONIlHwpPZSR",
        "outputId": "df1f74c0-2cb6-42a3-a7c7-9ba7cd1fd2ec"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "random forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bad       0.70      1.00      0.83       209\n",
            "        good       1.00      0.03      0.06        91\n",
            "\n",
            "    accuracy                           0.71       300\n",
            "   macro avg       0.85      0.52      0.44       300\n",
            "weighted avg       0.79      0.71      0.59       300\n",
            "\n",
            "[[209  88]\n",
            " [  0   3]]\n",
            "total cost:  88\n",
            " \n",
            "linear SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bad       0.70      1.00      0.82       209\n",
            "        good       0.00      0.00      0.00        91\n",
            "\n",
            "    accuracy                           0.70       300\n",
            "   macro avg       0.35      0.50      0.41       300\n",
            "weighted avg       0.49      0.70      0.57       300\n",
            "\n",
            "[[209  91]\n",
            " [  0   0]]\n",
            "total cost:  91\n",
            " \n",
            "gaussian naïve bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bad       0.84      0.79      0.82       209\n",
            "        good       0.58      0.65      0.61        91\n",
            "\n",
            "    accuracy                           0.75       300\n",
            "   macro avg       0.71      0.72      0.71       300\n",
            "weighted avg       0.76      0.75      0.75       300\n",
            "\n",
            "[[166  32]\n",
            " [ 43  59]]\n",
            "total cost:  247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}