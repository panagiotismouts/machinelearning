{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "BbtyLiQlWGLM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbtyLiQlWGLM",
    "outputId": "6d0191c3-f2bf-459e-82cc-ebc2fb129c44",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3371e960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (23.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b78650",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6b78650",
    "outputId": "8bb1384d-be99-48b9-c9c3-401e12038cd6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cap in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.4)\n",
      "Requirement already satisfied: bidict<0.23.0,>=0.22.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cap) (0.22.1)\n",
      "Requirement already satisfied: optbinning in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.17.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optbinning) (3.6.3)\n",
      "Requirement already satisfied: numpy>=1.16.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optbinning) (1.24.1)\n",
      "Requirement already satisfied: ortools>=9.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optbinning) (9.6.2534)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optbinning) (1.5.3)\n",
      "Requirement already satisfied: ropwr>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optbinning) (1.0.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optbinning) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optbinning) (1.10.0)\n",
      "Requirement already satisfied: absl-py>=0.13 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ortools>=9.4->optbinning) (1.4.0)\n",
      "Requirement already satisfied: protobuf>=4.21.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ortools>=9.4->optbinning) (4.23.2)\n",
      "Requirement already satisfied: cvxpy>=1.1.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ropwr>=1.0.0->optbinning) (1.3.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=1.0.2->optbinning) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=1.0.2->optbinning) (3.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->optbinning) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->optbinning) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->optbinning) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->optbinning) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->optbinning) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->optbinning) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->optbinning) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->optbinning) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->optbinning) (2022.7.1)\n",
      "Requirement already satisfied: osqp>=0.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cvxpy>=1.1.14->ropwr>=1.0.0->optbinning) (0.6.3)\n",
      "Requirement already satisfied: ecos>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cvxpy>=1.1.14->ropwr>=1.0.0->optbinning) (2.0.12)\n",
      "Requirement already satisfied: scs>=1.1.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cvxpy>=1.1.14->ropwr>=1.0.0->optbinning) (3.2.3)\n",
      "Requirement already satisfied: setuptools>65.5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cvxpy>=1.1.14->ropwr>=1.0.0->optbinning) (67.8.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->optbinning) (1.16.0)\n",
      "Requirement already satisfied: qdldl in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from osqp>=0.4.1->cvxpy>=1.1.14->ropwr>=1.0.0->optbinning) (0.1.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install cap\n",
    "!pip install optbinning\n",
    "# !pip install python-pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be0c059f",
   "metadata": {
    "id": "be0c059f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#global variables setting\n",
    "def globalvariables (dataset_number):\n",
    "  assert 1<= dataset_number <=3, 'dataset number has to be between 1 and 3'\n",
    "  path = \"C:/Users/user/Desktop/binning/\"\n",
    "  dataset_path = f\"{path}dataset_{dataset_number}_original.csv\"\n",
    "  results_path = f\"{path}dataset_{dataset_number}_results/\"\n",
    "  if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)\n",
    "  dataset_text = \"Optimal Binning Dataset \" + str(dataset_number)\n",
    "\n",
    "  return path, dataset_path, results_path, dataset_number, dataset_text\n",
    "\n",
    "path, dataset_path, results_path, dataset_number, dataset_text = globalvariables(1) ## insert number of each dataset\n",
    "VAR_BINNING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d575906",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d575906",
    "outputId": "bcad9a21-17b5-4b44-eaf7-0d7f0d23d226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247032, 250)\n",
      "(247032, 250)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load the dataset into a pandas dataframe\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "#################ONLY FOR DATASET 3######################################\n",
    "if dataset_number == 3:\n",
    "    df['RiskPerformance'] = df['RiskPerformance'].map({ 'Good': 0, 'Bad': 1})\n",
    "\n",
    "# identify the data types of each column in the dataframe\n",
    "dtypes = df.dtypes\n",
    "print(df.shape)\n",
    "\n",
    "# extract the names of the continuous variables\n",
    "continuous_vars = []\n",
    "for col in df.columns:\n",
    "    if dtypes[col] == \"float64\" or dtypes[col] == \"int64\":\n",
    "        continuous_vars.append(col)\n",
    "\n",
    "# create a new dataframe containing only the continuous variables\n",
    "df_continuous = df[continuous_vars]\n",
    "print(df_continuous.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A8NwSMfFkKqN",
   "metadata": {
    "id": "A8NwSMfFkKqN"
   },
   "source": [
    "Countries HomeCredit Bank operates in:\n",
    "- Czech Republic\n",
    "- Slovakia\n",
    "- Kazakhstan\n",
    "- China\n",
    "- Vietnam\n",
    "- India\n",
    "- Indonesia\n",
    "- Philippines\n",
    "\n",
    "Dataset is from 2018 but it was not possible to obtain the interest rates for this year for all countries for free, that's why we approximated with the interest rate 2018 in Czech Republic which was around 0.9%.\n",
    "\n",
    "The source for this rate is: https://data.worldbank.org/indicator/FR.INR.RINR?locations=CZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "zIVbBnhSVauO",
   "metadata": {
    "id": "zIVbBnhSVauO"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if dataset_number == 1:\n",
    "\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  # Create a figure and axis\n",
    "  fig, ax = plt.subplots()\n",
    "\n",
    "  # Plot the distribution using a histogram\n",
    "  ax.hist(df['AMT_CREDIT'], bins=20, edgecolor='black')\n",
    "\n",
    "  # Set labels and title\n",
    "  ax.set_xlabel('Credit Amount')\n",
    "  ax.set_ylabel('Frequency')\n",
    "  ax.set_title('Distribution of Credit Amount')\n",
    "  \n",
    "  # Show the plot\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hiO6prjPXbnX",
   "metadata": {
    "id": "hiO6prjPXbnX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (with outliers): 598463.1846036142\n",
      "Mean (without top 1% quantile): 585947.0281149338\n"
     ]
    }
   ],
   "source": [
    "if dataset_number == 1:\n",
    "  # Calculate the 99% quantile value\n",
    "  quantile_99 = df['AMT_CREDIT'].quantile(0.99)\n",
    "\n",
    "  # Exclude values above the 99% quantile\n",
    "  df_no_outliers = df[df['AMT_CREDIT'] <= quantile_99]\n",
    "\n",
    "  # Calculate the mean without the top 1% quantile values\n",
    "  mean_no_outliers = df_no_outliers['AMT_CREDIT'].mean()\n",
    "\n",
    "  print(\"Mean (with outliers):\", df['AMT_CREDIT'].mean())\n",
    "  print(\"Mean (without top 1% quantile):\", mean_no_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "o5-KZGqVC0M7",
   "metadata": {
    "id": "o5-KZGqVC0M7"
   },
   "outputs": [],
   "source": [
    "if dataset_number == 1:\n",
    "  cost_for_fn = mean_no_outliers\n",
    "\n",
    "  interest_rate = 0.9\n",
    "  cost_for_fp = df['AMT_CREDIT'].mean() * interest_rate / 100\n",
    "\n",
    "  cost_m = [[0, cost_for_fp],\n",
    "            [cost_for_fn, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cx27bz41ZQiv",
   "metadata": {
    "id": "cx27bz41ZQiv"
   },
   "outputs": [],
   "source": [
    "cost_m = [[0, 5386.168661432527], [585947.0281149338, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff119329",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "ff119329",
    "outputId": "82f916b6-cff0-4169-a196-fe1bc7420a53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>day_to_actual_payment_count</th>\n",
       "      <th>max_days_of_delay</th>\n",
       "      <th>nummber_of_applications</th>\n",
       "      <th>Consumer loans</th>\n",
       "      <th>Cash loans</th>\n",
       "      <th>Revolving loans</th>\n",
       "      <th>XNA</th>\n",
       "      <th>Approved</th>\n",
       "      <th>Refused</th>\n",
       "      <th>...</th>\n",
       "      <th>FONDKAPREMONT_MODE_reg oper spec account</th>\n",
       "      <th>HOUSETYPE_MODE_specific housing</th>\n",
       "      <th>HOUSETYPE_MODE_terraced house</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "      <td>247032.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>278155.858618</td>\n",
       "      <td>27.743976</td>\n",
       "      <td>38.293254</td>\n",
       "      <td>4.998612</td>\n",
       "      <td>2.223696</td>\n",
       "      <td>2.217389</td>\n",
       "      <td>0.556406</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>3.123413</td>\n",
       "      <td>0.876676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039218</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>0.723720</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>0.017714</td>\n",
       "      <td>0.007691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>102862.182082</td>\n",
       "      <td>24.366741</td>\n",
       "      <td>29.478101</td>\n",
       "      <td>4.218016</td>\n",
       "      <td>1.844395</td>\n",
       "      <td>3.291494</td>\n",
       "      <td>1.020010</td>\n",
       "      <td>0.036477</td>\n",
       "      <td>2.147287</td>\n",
       "      <td>1.851184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194113</td>\n",
       "      <td>0.070159</td>\n",
       "      <td>0.063051</td>\n",
       "      <td>0.085494</td>\n",
       "      <td>0.074694</td>\n",
       "      <td>0.072186</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>0.407586</td>\n",
       "      <td>0.131911</td>\n",
       "      <td>0.087362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100002.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>189000.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>278094.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>367318.250000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>456255.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>3189.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SK_ID_CURR  day_to_actual_payment_count  max_days_of_delay  \\\n",
       "count  247032.000000                247032.000000      247032.000000   \n",
       "mean   278155.858618                    27.743976          38.293254   \n",
       "std    102862.182082                    24.366741          29.478101   \n",
       "min    100002.000000                     0.000000         -25.000000   \n",
       "25%    189000.500000                    11.000000          23.000000   \n",
       "50%    278094.500000                    20.000000          32.000000   \n",
       "75%    367318.250000                    37.000000          44.000000   \n",
       "max    456255.000000                   245.000000        3189.000000   \n",
       "\n",
       "       nummber_of_applications  Consumer loans     Cash loans  \\\n",
       "count            247032.000000   247032.000000  247032.000000   \n",
       "mean                  4.998612        2.223696       2.217389   \n",
       "std                   4.218016        1.844395       3.291494   \n",
       "min                   1.000000        0.000000       0.000000   \n",
       "25%                   2.000000        1.000000       0.000000   \n",
       "50%                   4.000000        2.000000       1.000000   \n",
       "75%                   7.000000        3.000000       3.000000   \n",
       "max                  73.000000       45.000000      60.000000   \n",
       "\n",
       "       Revolving loans            XNA       Approved        Refused  ...  \\\n",
       "count    247032.000000  247032.000000  247032.000000  247032.000000  ...   \n",
       "mean          0.556406       0.001121       3.123413       0.876676  ...   \n",
       "std           1.020010       0.036477       2.147287       1.851184  ...   \n",
       "min           0.000000       0.000000       0.000000       0.000000  ...   \n",
       "25%           0.000000       0.000000       2.000000       0.000000  ...   \n",
       "50%           0.000000       0.000000       3.000000       0.000000  ...   \n",
       "75%           1.000000       0.000000       4.000000       1.000000  ...   \n",
       "max          31.000000       3.000000      27.000000      68.000000  ...   \n",
       "\n",
       "       FONDKAPREMONT_MODE_reg oper spec account  \\\n",
       "count                             247032.000000   \n",
       "mean                                   0.039218   \n",
       "std                                    0.194113   \n",
       "min                                    0.000000   \n",
       "25%                                    0.000000   \n",
       "50%                                    0.000000   \n",
       "75%                                    0.000000   \n",
       "max                                    1.000000   \n",
       "\n",
       "       HOUSETYPE_MODE_specific housing  HOUSETYPE_MODE_terraced house  \\\n",
       "count                    247032.000000                  247032.000000   \n",
       "mean                          0.004947                       0.003991   \n",
       "std                           0.070159                       0.063051   \n",
       "min                           0.000000                       0.000000   \n",
       "25%                           0.000000                       0.000000   \n",
       "50%                           0.000000                       0.000000   \n",
       "75%                           0.000000                       0.000000   \n",
       "max                           1.000000                       1.000000   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Mixed  WALLSMATERIAL_MODE_Monolithic  \\\n",
       "count             247032.000000                  247032.000000   \n",
       "mean                   0.007363                       0.005611   \n",
       "std                    0.085494                       0.074694   \n",
       "min                    0.000000                       0.000000   \n",
       "25%                    0.000000                       0.000000   \n",
       "50%                    0.000000                       0.000000   \n",
       "75%                    0.000000                       0.000000   \n",
       "max                    1.000000                       1.000000   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Others  WALLSMATERIAL_MODE_Panel  \\\n",
       "count              247032.000000             247032.000000   \n",
       "mean                    0.005238                  0.723720   \n",
       "std                     0.072186                  0.447158   \n",
       "min                     0.000000                  0.000000   \n",
       "25%                     0.000000                  0.000000   \n",
       "50%                     0.000000                  1.000000   \n",
       "75%                     0.000000                  1.000000   \n",
       "max                     1.000000                  1.000000   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Stone, brick  WALLSMATERIAL_MODE_Wooden  \\\n",
       "count                    247032.000000              247032.000000   \n",
       "mean                          0.210390                   0.017714   \n",
       "std                           0.407586                   0.131911   \n",
       "min                           0.000000                   0.000000   \n",
       "25%                           0.000000                   0.000000   \n",
       "50%                           0.000000                   0.000000   \n",
       "75%                           0.000000                   0.000000   \n",
       "max                           1.000000                   1.000000   \n",
       "\n",
       "       EMERGENCYSTATE_MODE_Yes  \n",
       "count            247032.000000  \n",
       "mean                  0.007691  \n",
       "std                   0.087362  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   0.000000  \n",
       "75%                   0.000000  \n",
       "max                   1.000000  \n",
       "\n",
       "[8 rows x 250 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def describex(data):\n",
    "    data = pd.DataFrame(data)\n",
    "    stats = data.describe()\n",
    "    skewness = data.skew()\n",
    "    kurtosis = data.kurtosis()\n",
    "    skewness_df = pd.DataFrame({'skewness':skewness}).T\n",
    "    kurtosis_df = pd.DataFrame({'kurtosis':kurtosis}).T\n",
    "    pd.concat([kurtosis_df,skewness_df,stats])\n",
    "    return stats\n",
    "  \n",
    "describex(df_continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d38e87b7",
   "metadata": {
    "id": "d38e87b7"
   },
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "#del cap\n",
    "\n",
    "#the first dataset is called df.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#handling the target column.\n",
    "if dataset_number == 1:\n",
    "    target='TARGET'\n",
    "elif dataset_number == 2:\n",
    "    target='default payment next month'\n",
    "elif dataset_number == 3:\n",
    "    target='RiskPerformance'\n",
    "\n",
    "X = df.loc[:,df.columns.drop(target)]\n",
    "y = df.loc[:,target]\n",
    "\n",
    "X_train, X_remainder, y_train, y_remainder = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "X_test, X_validate, y_test, y_validate = train_test_split(X_remainder, y_remainder, test_size=0.5, random_state=0)\n",
    "\n",
    "train_count = len(X_train)\n",
    "test_count = len(X_test)\n",
    "validate_count = len(X_validate)\n",
    "\n",
    "total_count = len(X)\n",
    "train_percent = (train_count / total_count) * 100\n",
    "test_percent = (test_count / total_count) * 100\n",
    "validate_percent = (validate_count / total_count) * 100\n",
    "\n",
    "print(f\"Train: {train_percent:.2f}% ({train_count} samples)\")\n",
    "print(f\"Test: {test_percent:.2f}% ({test_count} samples)\")\n",
    "print(f\"Validate: {validate_percent:.2f}% ({validate_count} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ULf3d5Xfpla8",
   "metadata": {
    "id": "ULf3d5Xfpla8"
   },
   "outputs": [],
   "source": [
    "with open(f\"{results_path}train_test_validate_split.txt\", 'w') as f:\n",
    "    f.write(str(cap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bdb3259",
   "metadata": {
    "id": "0bdb3259"
   },
   "outputs": [],
   "source": [
    "#!rm -rf figs\n",
    "# !rmdir /s figs -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4208db2",
   "metadata": {
    "id": "f4208db2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_binned[column] = binning.transform(X_train[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_binned[column] = binning.transform(X_test[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14516\\1009377476.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_val_binned[column] = binning.transform(X_validate[column].values)\n"
     ]
    }
   ],
   "source": [
    "%%capture cap --no-stderr\n",
    "if VAR_BINNING == True:\n",
    "  #del cap\n",
    "\n",
    "  from optbinning import ContinuousOptimalBinning, OptimalBinning\n",
    "  import os\n",
    "  import re\n",
    "\n",
    "  dict_tab = {}\n",
    "  dict_woe_plot = {}\n",
    "  dict_er_plot = {}\n",
    "  dict_qs = {}\n",
    "  dict_gini = {}\n",
    "  direc = results_path + \"binning_plots\" #for google colab, change to \"./figs\" to create locally.\n",
    "  if not os.path.exists(direc):\n",
    "      os.makedirs(direc)\n",
    "  os.makedirs(direc, exist_ok=True)\n",
    "\n",
    "  #fitting the binner ONLY using X_train\n",
    "  for column in X_train.columns:\n",
    "      plot_path = ''\n",
    "\n",
    "      binning = OptimalBinning(name=column, solver=\"cp\", dtype=\"numerical\", monotonic_trend=\"auto_asc_desc\")\n",
    "      binning.fit(X_train[column].values, y_train.values)\n",
    "      #print(binning.status)\n",
    "\n",
    "      binning_table = binning.binning_table #PPT\n",
    "      tab = binning_table.build()#creating the binning table\n",
    "      dict_tab.update({column:tab})#insert the table on the dictionary for X column\n",
    "\n",
    "      #########################################################\n",
    "      ####################    PLOTS     #######################\n",
    "      if re.search(\"/\", column):\n",
    "          # Remove invalid characters from column name to use as filename\n",
    "          plot_filename_woe = re.sub(r'[<>:\"/\\\\|?*]', \"\", column) + '_WOE.png'\n",
    "      else:\n",
    "          plot_filename_woe = column + '_WOE.png'\n",
    "\n",
    "      plot_path_woe = os.path.join(direc, plot_filename_woe)\n",
    "      binning_table.plot(metric=\"woe\", savefig=plot_path_woe) #show_bin_labels=True, to show bin labels.\n",
    "\n",
    "      if re.search(\"/\", column):\n",
    "          # Remove invalid characters from column name to use as filename\n",
    "          plot_filename_er = re.sub(r'[<>:\"/\\\\|?*]', \"\", column) + '_ER.png'\n",
    "      else:\n",
    "          plot_filename_er = column + '_ER.png'\n",
    "\n",
    "      plot_path_er = os.path.join(direc, plot_filename_er)\n",
    "\n",
    "      binning_table.plot(metric=\"event_rate\", savefig=plot_path_er)\n",
    "\n",
    "      dict_woe_plot.update({column: plot_path_woe})\n",
    "      dict_er_plot.update({column: plot_path_er})\n",
    "\n",
    "      binning_table.analysis()\n",
    "      dict_qs.update({column:round(binning_table.quality_score*1000, 2)})\n",
    "      dict_gini.update({column:round(binning_table.gini, 5)})\n",
    "\n",
    "  #transformations\n",
    "  X_train_binned = pd.DataFrame()\n",
    "  for column in X_train.columns:\n",
    "      binning = OptimalBinning(name=column, solver=\"cp\", dtype=\"numerical\", monotonic_trend=\"auto_asc_desc\")\n",
    "      binning.fit(X_train[column].values, y_train.values)\n",
    "      X_train_binned[column] = binning.transform(X_train[column].values)\n",
    "\n",
    "  # Applying binning transformation on X_test\n",
    "  X_test_binned = pd.DataFrame()\n",
    "  for column in X_test.columns:\n",
    "      binning = OptimalBinning(name=column, solver=\"cp\", dtype=\"numerical\", monotonic_trend=\"auto_asc_desc\")\n",
    "      binning.fit(X_train[column].values, y_train.values)\n",
    "      X_test_binned[column] = binning.transform(X_test[column].values)\n",
    "\n",
    "  # Applying binning transformation on X_validate\n",
    "  X_val_binned = pd.DataFrame()\n",
    "  for column in X_validate.columns:\n",
    "      binning = OptimalBinning(name=column, solver=\"cp\", dtype=\"numerical\", monotonic_trend=\"auto_asc_desc\")\n",
    "      binning.fit(X_train[column].values, y_train.values)\n",
    "      X_val_binned[column] = binning.transform(X_validate[column].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2EfXQWDrsgy9",
   "metadata": {
    "id": "2EfXQWDrsgy9"
   },
   "outputs": [],
   "source": [
    "if VAR_BINNING == True:\n",
    "  with open(f\"{results_path}binning_results.txt\", 'w') as f:\n",
    "      f.write(str(cap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "120d020f",
   "metadata": {
    "id": "120d020f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SK_ID_CURR  day_to_actual_payment_count  max_days_of_delay  \\\n",
      "0    0.003935                     0.192322          -0.027826   \n",
      "1    0.003935                     0.192322           0.024297   \n",
      "2    0.003935                    -0.062381          -0.027826   \n",
      "3    0.003935                     0.192322          -0.027826   \n",
      "4    0.003935                    -0.163894          -0.031401   \n",
      "\n",
      "   nummber_of_applications  Consumer loans  Cash loans  Revolving loans  \\\n",
      "0                -0.106133        0.153042   -0.000091        -0.380405   \n",
      "1                -0.281836        0.153042   -0.244489         0.116868   \n",
      "2                 0.033678       -0.081015   -0.028261         0.116868   \n",
      "3                -0.106133       -0.081015   -0.244489         0.116868   \n",
      "4                 0.047450       -0.081015    0.077099         0.116868   \n",
      "\n",
      "            XNA  Approved   Refused  Canceled  Unused offer  \\\n",
      "0  2.220446e-16  0.190855 -0.080871 -0.124921  2.220446e-16   \n",
      "1  2.220446e-16  0.206011 -0.246449 -0.124921  2.220446e-16   \n",
      "2  2.220446e-16 -0.115651 -0.080871 -0.124921  2.220446e-16   \n",
      "3  2.220446e-16 -0.094750 -0.495034 -0.058126  2.220446e-16   \n",
      "4  2.220446e-16 -0.115651  0.172744  0.053253  2.220446e-16   \n",
      "\n",
      "   max_previous_delayed_days  max_previous_anuity_to_credit  SK_DPD_DEF_count  \\\n",
      "0                   0.022690                      -0.058043         -0.003257   \n",
      "1                   0.022690                       0.072512         -0.003257   \n",
      "2                   0.022690                      -0.164289         -0.003257   \n",
      "3                  -0.001696                      -0.058043         -0.003257   \n",
      "4                   0.022690                      -0.058043          0.033213   \n",
      "\n",
      "   SK_DPD_DEF_max    Closed    Active          Sold      Bad debt  \\\n",
      "0       -0.003257  0.121135  0.026279  2.220446e-16  2.220446e-16   \n",
      "1       -0.003257 -0.100399  0.093846  2.220446e-16  2.220446e-16   \n",
      "2       -0.003257  0.150759 -0.045787  2.220446e-16  2.220446e-16   \n",
      "3       -0.003257  0.150759 -0.469793  2.220446e-16  2.220446e-16   \n",
      "4        0.033213 -0.400291  0.093846  2.220446e-16  2.220446e-16   \n",
      "\n",
      "   max_days_delayed  max_amount_delayed  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
      "0      2.220446e-16        2.220446e-16      0.049174         -0.045260   \n",
      "1      2.220446e-16        2.220446e-16      0.049174         -0.045260   \n",
      "2      2.220446e-16        2.220446e-16      0.049174          0.279268   \n",
      "3      2.220446e-16        2.220446e-16      0.049174          0.155535   \n",
      "4      2.220446e-16        2.220446e-16      0.049174         -0.045260   \n",
      "\n",
      "   AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  \\\n",
      "0    0.079792     0.248946         0.229332                   -0.063476   \n",
      "1   -0.098644    -0.044333        -0.160649                   -0.063476   \n",
      "2   -0.098644    -0.044333        -0.160649                   -0.063476   \n",
      "3    0.118144    -0.044333         0.229332                    0.021879   \n",
      "4    0.079792     0.022324         0.041204                   -0.145218   \n",
      "\n",
      "   DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  OWN_CAR_AGE  \\\n",
      "0    0.052069      -0.139665          -0.076426         0.217803    -0.057049   \n",
      "1    0.678099      -0.139665           0.467943         0.351670    -0.057049   \n",
      "2    0.235594      -0.139665           0.211317        -0.006188     0.376439   \n",
      "3    0.427983       0.637677           0.075191         0.217803     0.376439   \n",
      "4   -0.403555      -0.139665          -0.076426        -0.132968    -0.057049   \n",
      "\n",
      "     FLAG_MOBIL  FLAG_EMP_PHONE  FLAG_WORK_PHONE  FLAG_CONT_MOBILE  \\\n",
      "0  2.220446e-16        0.434138         0.049032      2.220446e-16   \n",
      "1  2.220446e-16        0.434138         0.049032      2.220446e-16   \n",
      "2  2.220446e-16       -0.076397         0.049032      2.220446e-16   \n",
      "3  2.220446e-16       -0.076397         0.049032      2.220446e-16   \n",
      "4  2.220446e-16       -0.076397         0.049032      2.220446e-16   \n",
      "\n",
      "   FLAG_PHONE  FLAG_EMAIL  CNT_FAM_MEMBERS  REGION_RATING_CLIENT  \\\n",
      "0   -0.059882   -0.001395         0.035303              0.031098   \n",
      "1   -0.059882   -0.001395         0.035303              0.031098   \n",
      "2   -0.059882   -0.001395         0.035303              0.031098   \n",
      "3   -0.059882   -0.001395         0.035303              0.031098   \n",
      "4   -0.059882   -0.001395         0.035303              0.031098   \n",
      "\n",
      "   REGION_RATING_CLIENT_W_CITY  HOUR_APPR_PROCESS_START  \\\n",
      "0                     0.026624                 0.001942   \n",
      "1                     0.026624                 0.011376   \n",
      "2                     0.026624                 0.048209   \n",
      "3                     0.026624                -0.011120   \n",
      "4                     0.026624                 0.167367   \n",
      "\n",
      "   REG_REGION_NOT_LIVE_REGION  REG_REGION_NOT_WORK_REGION  \\\n",
      "0                2.220446e-16                2.220446e-16   \n",
      "1                2.220446e-16                2.220446e-16   \n",
      "2                2.220446e-16                2.220446e-16   \n",
      "3                2.220446e-16                2.220446e-16   \n",
      "4                2.220446e-16                2.220446e-16   \n",
      "\n",
      "   LIVE_REGION_NOT_WORK_REGION  REG_CITY_NOT_LIVE_CITY  \\\n",
      "0                 2.220446e-16                0.044325   \n",
      "1                 2.220446e-16                0.044325   \n",
      "2                 2.220446e-16                0.044325   \n",
      "3                 2.220446e-16                0.044325   \n",
      "4                 2.220446e-16                0.044325   \n",
      "\n",
      "   REG_CITY_NOT_WORK_CITY  LIVE_CITY_NOT_WORK_CITY  EXT_SOURCE_1  \\\n",
      "0                0.096441                 0.051200     -0.031220   \n",
      "1                0.096441                 0.051200     -0.031220   \n",
      "2               -0.280605                -0.211138     -0.031220   \n",
      "3                0.096441                 0.051200      0.369785   \n",
      "4               -0.280605                -0.211138     -0.760456   \n",
      "\n",
      "   EXT_SOURCE_2  EXT_SOURCE_3  APARTMENTS_AVG  BASEMENTAREA_AVG  \\\n",
      "0      0.004507     -0.283100       -0.120452         -0.045929   \n",
      "1      0.964877      0.991094       -0.039206         -0.045929   \n",
      "2      0.330105     -0.568274       -0.039206         -0.045929   \n",
      "3     -0.637213      0.108938        0.225379          0.216211   \n",
      "4     -0.117858     -0.189590       -0.039206         -0.045929   \n",
      "\n",
      "   YEARS_BEGINEXPLUATATION_AVG  YEARS_BUILD_AVG  COMMONAREA_AVG  \\\n",
      "0                    -0.090849        -0.043254       -0.017168   \n",
      "1                    -0.090849        -0.043254       -0.017168   \n",
      "2                    -0.090849        -0.043254       -0.017168   \n",
      "3                     0.234929         0.321267        0.265388   \n",
      "4                    -0.090849        -0.043254       -0.017168   \n",
      "\n",
      "   ELEVATORS_AVG  ENTRANCES_AVG  FLOORSMAX_AVG  FLOORSMIN_AVG  LANDAREA_AVG  \\\n",
      "0      -0.058916      -0.049060      -0.123440      -0.034690     -0.034229   \n",
      "1      -0.058916      -0.049060      -0.057990      -0.034690     -0.034229   \n",
      "2      -0.058916      -0.049060      -0.057990      -0.034690     -0.034229   \n",
      "3       0.298986       0.255557       0.277005       0.354029      0.176961   \n",
      "4      -0.058916      -0.049060      -0.057990      -0.034690     -0.034229   \n",
      "\n",
      "   LIVINGAPARTMENTS_AVG  LIVINGAREA_AVG  NONLIVINGAPARTMENTS_AVG  \\\n",
      "0             -0.112454       -0.147278                -0.011632   \n",
      "1             -0.023105       -0.041202                -0.011632   \n",
      "2             -0.023105       -0.041202                -0.011632   \n",
      "3              0.162735        0.401502                -0.011632   \n",
      "4             -0.023105       -0.041202                -0.011632   \n",
      "\n",
      "   NONLIVINGAREA_AVG  APARTMENTS_MODE  BASEMENTAREA_MODE  \\\n",
      "0          -0.022329        -0.113202          -0.040330   \n",
      "1          -0.022329        -0.037107          -0.040330   \n",
      "2          -0.022329        -0.037107          -0.040330   \n",
      "3          -0.022329         0.190904           0.187475   \n",
      "4          -0.022329        -0.037107          -0.040330   \n",
      "\n",
      "   YEARS_BEGINEXPLUATATION_MODE  YEARS_BUILD_MODE  COMMONAREA_MODE  \\\n",
      "0                      0.096528         -0.042469        -0.016496   \n",
      "1                     -0.102543         -0.042469        -0.016496   \n",
      "2                     -0.102543         -0.042469        -0.016496   \n",
      "3                      0.255827          0.337728         0.273331   \n",
      "4                     -0.102543         -0.042469        -0.016496   \n",
      "\n",
      "   ELEVATORS_MODE  ENTRANCES_MODE  FLOORSMAX_MODE  FLOORSMIN_MODE  \\\n",
      "0       -0.055598       -0.043810       -0.091430       -0.032857   \n",
      "1       -0.055598       -0.043810       -0.057269       -0.032857   \n",
      "2       -0.055598       -0.043810       -0.057269       -0.032857   \n",
      "3        0.291898        0.236902        0.281486        0.354678   \n",
      "4       -0.055598       -0.043810       -0.057269       -0.032857   \n",
      "\n",
      "   LANDAREA_MODE  LIVINGAPARTMENTS_MODE  LIVINGAREA_MODE  \\\n",
      "0      -0.030065              -0.095921        -0.131797   \n",
      "1      -0.030065              -0.023943        -0.039275   \n",
      "2      -0.030065              -0.023943        -0.039275   \n",
      "3      -0.030065               0.193081         0.403484   \n",
      "4      -0.030065              -0.023943        -0.039275   \n",
      "\n",
      "   NONLIVINGAPARTMENTS_MODE  NONLIVINGAREA_MODE  APARTMENTS_MEDI  \\\n",
      "0                  0.100146            0.142325        -0.121349   \n",
      "1                 -0.043533           -0.066927        -0.037479   \n",
      "2                 -0.043533           -0.066927        -0.037479   \n",
      "3                  0.146128            0.142325         0.225205   \n",
      "4                 -0.043533           -0.066927        -0.037479   \n",
      "\n",
      "   BASEMENTAREA_MEDI  YEARS_BEGINEXPLUATATION_MEDI  YEARS_BUILD_MEDI  \\\n",
      "0          -0.044820                     -0.090769         -0.043101   \n",
      "1          -0.044820                     -0.090769         -0.043101   \n",
      "2          -0.044820                     -0.090769         -0.043101   \n",
      "3           0.204921                      0.235322          0.324202   \n",
      "4          -0.044820                     -0.090769         -0.043101   \n",
      "\n",
      "   COMMONAREA_MEDI  ELEVATORS_MEDI  ENTRANCES_MEDI  FLOORSMAX_MEDI  \\\n",
      "0        -0.016987       -0.058175       -0.047592       -0.123466   \n",
      "1        -0.016987       -0.058175       -0.047592       -0.057637   \n",
      "2        -0.016987       -0.058175       -0.047592       -0.057637   \n",
      "3         0.265369        0.297161        0.246893        0.277912   \n",
      "4        -0.016987       -0.058175       -0.047592       -0.057637   \n",
      "\n",
      "   FLOORSMIN_MEDI  LANDAREA_MEDI  LIVINGAPARTMENTS_MEDI  LIVINGAREA_MEDI  \\\n",
      "0       -0.033800      -0.033463              -0.110995        -0.148196   \n",
      "1       -0.033800      -0.033463              -0.022933        -0.039987   \n",
      "2       -0.033800      -0.033463              -0.022933        -0.039987   \n",
      "3        0.351343       0.200932               0.167667         0.401360   \n",
      "4       -0.033800      -0.033463              -0.022933        -0.039987   \n",
      "\n",
      "   NONLIVINGAPARTMENTS_MEDI  NONLIVINGAREA_MEDI  TOTALAREA_MODE  \\\n",
      "0                  0.089982            0.144630       -0.123035   \n",
      "1                 -0.042691           -0.067369       -0.046737   \n",
      "2                 -0.042691           -0.067369       -0.046737   \n",
      "3                  0.150771            0.144630        0.262245   \n",
      "4                 -0.042691           -0.067369       -0.046737   \n",
      "\n",
      "   OBS_30_CNT_SOCIAL_CIRCLE  DEF_30_CNT_SOCIAL_CIRCLE  \\\n",
      "0                 -0.031569                  0.038884   \n",
      "1                  0.022451                 -0.264726   \n",
      "2                  0.022451                  0.038884   \n",
      "3                  0.022451                  0.038884   \n",
      "4                  0.022451                  0.038884   \n",
      "\n",
      "   OBS_60_CNT_SOCIAL_CIRCLE  DEF_60_CNT_SOCIAL_CIRCLE  DAYS_LAST_PHONE_CHANGE  \\\n",
      "0                 -0.032578                  0.031941               -0.193667   \n",
      "1                  0.022896                 -0.303784                0.470113   \n",
      "2                  0.022896                  0.031941               -0.056199   \n",
      "3                  0.022896                  0.031941                0.119496   \n",
      "4                  0.022896                  0.031941               -0.193667   \n",
      "\n",
      "   FLAG_DOCUMENT_2  FLAG_DOCUMENT_3  FLAG_DOCUMENT_4  FLAG_DOCUMENT_5  \\\n",
      "0     2.220446e-16        -0.094558     2.220446e-16     2.220446e-16   \n",
      "1     2.220446e-16        -0.094558     2.220446e-16     2.220446e-16   \n",
      "2     2.220446e-16         0.286156     2.220446e-16     2.220446e-16   \n",
      "3     2.220446e-16        -0.094558     2.220446e-16     2.220446e-16   \n",
      "4     2.220446e-16         0.286156     2.220446e-16     2.220446e-16   \n",
      "\n",
      "   FLAG_DOCUMENT_6  FLAG_DOCUMENT_7  FLAG_DOCUMENT_8  FLAG_DOCUMENT_9  \\\n",
      "0        -0.031576     2.220446e-16        -0.006813     2.220446e-16   \n",
      "1        -0.031576     2.220446e-16        -0.006813     2.220446e-16   \n",
      "2        -0.031576     2.220446e-16         0.080425     2.220446e-16   \n",
      "3        -0.031576     2.220446e-16        -0.006813     2.220446e-16   \n",
      "4        -0.031576     2.220446e-16        -0.006813     2.220446e-16   \n",
      "\n",
      "   FLAG_DOCUMENT_10  FLAG_DOCUMENT_11  FLAG_DOCUMENT_12  FLAG_DOCUMENT_13  \\\n",
      "0      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "1      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "2      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "3      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "4      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "\n",
      "   FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  FLAG_DOCUMENT_17  \\\n",
      "0      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "1      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "2      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "3      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "4      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "\n",
      "   FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  \\\n",
      "0      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "1      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "2      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "3      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "4      2.220446e-16      2.220446e-16      2.220446e-16      2.220446e-16   \n",
      "\n",
      "   AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
      "0                2.220446e-16               2.220446e-16   \n",
      "1                2.220446e-16               2.220446e-16   \n",
      "2                2.220446e-16               2.220446e-16   \n",
      "3                2.220446e-16               2.220446e-16   \n",
      "4                2.220446e-16               2.220446e-16   \n",
      "\n",
      "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
      "0                2.220446e-16                  -0.015326   \n",
      "1                2.220446e-16                  -0.015326   \n",
      "2                2.220446e-16                  -0.015326   \n",
      "3                2.220446e-16                  -0.015326   \n",
      "4                2.220446e-16                   0.078243   \n",
      "\n",
      "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \\\n",
      "0                  -0.023952                   -0.154882   \n",
      "1                   0.102496                   -0.019928   \n",
      "2                  -0.023952                    0.056758   \n",
      "3                  -0.023952                   -0.154882   \n",
      "4                  -0.023952                    0.056758   \n",
      "\n",
      "   percentage_of_credit_to_income  percentage_of_annuity_to_income  \\\n",
      "0                       -0.007866                        -0.068573   \n",
      "1                       -0.032524                        -0.054131   \n",
      "2                       -0.032524                         0.105493   \n",
      "3                       -0.007866                        -0.008360   \n",
      "4                       -0.007866                        -0.068573   \n",
      "\n",
      "   NAME_CONTRACT_TYPE_Revolving loans  CODE_GENDER_M  CODE_GENDER_XNA  \\\n",
      "0                            -0.03575       0.139679     2.220446e-16   \n",
      "1                            -0.03575       0.139679     2.220446e-16   \n",
      "2                            -0.03575      -0.239815     2.220446e-16   \n",
      "3                            -0.03575      -0.239815     2.220446e-16   \n",
      "4                            -0.03575       0.139679     2.220446e-16   \n",
      "\n",
      "   FLAG_OWN_CAR_Y  FLAG_OWN_REALTY_Y  NAME_TYPE_SUITE_Family  \\\n",
      "0       -0.061711          -0.063983                0.082732   \n",
      "1       -0.061711           0.027779                0.082732   \n",
      "2        0.125504           0.027779               -0.011816   \n",
      "3        0.125504           0.027779               -0.011816   \n",
      "4       -0.061711           0.027779                0.082732   \n",
      "\n",
      "   NAME_TYPE_SUITE_Group of people  NAME_TYPE_SUITE_Other_A  \\\n",
      "0                     2.220446e-16             2.220446e-16   \n",
      "1                     2.220446e-16             2.220446e-16   \n",
      "2                     2.220446e-16             2.220446e-16   \n",
      "3                     2.220446e-16             2.220446e-16   \n",
      "4                     2.220446e-16             2.220446e-16   \n",
      "\n",
      "   NAME_TYPE_SUITE_Other_B  NAME_TYPE_SUITE_Spouse, partner  \\\n",
      "0             2.220446e-16                     2.220446e-16   \n",
      "1             2.220446e-16                     2.220446e-16   \n",
      "2             2.220446e-16                     2.220446e-16   \n",
      "3             2.220446e-16                     2.220446e-16   \n",
      "4             2.220446e-16                     2.220446e-16   \n",
      "\n",
      "   NAME_TYPE_SUITE_Unaccompanied  NAME_INCOME_TYPE_Pensioner  \\\n",
      "0                       0.061317                    0.434946   \n",
      "1                       0.061317                    0.434946   \n",
      "2                       0.061317                   -0.076514   \n",
      "3                      -0.013454                   -0.076514   \n",
      "4                       0.061317                   -0.076514   \n",
      "\n",
      "   NAME_INCOME_TYPE_State servant  NAME_INCOME_TYPE_Student  \\\n",
      "0                       -0.025184              2.220446e-16   \n",
      "1                       -0.025184              2.220446e-16   \n",
      "2                       -0.025184              2.220446e-16   \n",
      "3                       -0.025184              2.220446e-16   \n",
      "4                       -0.025184              2.220446e-16   \n",
      "\n",
      "   NAME_INCOME_TYPE_Unemployed  NAME_INCOME_TYPE_Working  \\\n",
      "0                 2.220446e-16                  0.226659   \n",
      "1                 2.220446e-16                  0.226659   \n",
      "2                 2.220446e-16                 -0.175176   \n",
      "3                 2.220446e-16                 -0.175176   \n",
      "4                 2.220446e-16                 -0.175176   \n",
      "\n",
      "   NAME_EDUCATION_TYPE_Higher education  \\\n",
      "0                             -0.105481   \n",
      "1                             -0.105481   \n",
      "2                             -0.105481   \n",
      "3                              0.413051   \n",
      "4                              0.413051   \n",
      "\n",
      "   NAME_EDUCATION_TYPE_Incomplete higher  NAME_EDUCATION_TYPE_Lower secondary  \\\n",
      "0                           2.220446e-16                         2.220446e-16   \n",
      "1                           2.220446e-16                         2.220446e-16   \n",
      "2                           2.220446e-16                         2.220446e-16   \n",
      "3                           2.220446e-16                         2.220446e-16   \n",
      "4                           2.220446e-16                         2.220446e-16   \n",
      "\n",
      "   NAME_EDUCATION_TYPE_Secondary / secondary special  \\\n",
      "0                                           0.310792   \n",
      "1                                          -0.104377   \n",
      "2                                          -0.104377   \n",
      "3                                           0.310792   \n",
      "4                                           0.310792   \n",
      "\n",
      "   NAME_FAMILY_STATUS_Married  NAME_FAMILY_STATUS_Separated  \\\n",
      "0                    0.055176                     -0.002922   \n",
      "1                   -0.095448                     -0.002922   \n",
      "2                   -0.095448                      0.042535   \n",
      "3                    0.055176                     -0.002922   \n",
      "4                    0.055176                     -0.002922   \n",
      "\n",
      "   NAME_FAMILY_STATUS_Single / not married  NAME_FAMILY_STATUS_Widow  \\\n",
      "0                                 0.036258                 -0.016658   \n",
      "1                                 0.036258                  0.346483   \n",
      "2                                 0.036258                 -0.016658   \n",
      "3                                 0.036258                 -0.016658   \n",
      "4                                 0.036258                 -0.016658   \n",
      "\n",
      "   NAME_HOUSING_TYPE_House / apartment  NAME_HOUSING_TYPE_Municipal apartment  \\\n",
      "0                             0.038585                           2.220446e-16   \n",
      "1                             0.038585                           2.220446e-16   \n",
      "2                             0.038585                           2.220446e-16   \n",
      "3                             0.038585                           2.220446e-16   \n",
      "4                             0.038585                           2.220446e-16   \n",
      "\n",
      "   NAME_HOUSING_TYPE_Office apartment  NAME_HOUSING_TYPE_Rented apartment  \\\n",
      "0                        2.220446e-16                        2.220446e-16   \n",
      "1                        2.220446e-16                        2.220446e-16   \n",
      "2                        2.220446e-16                        2.220446e-16   \n",
      "3                        2.220446e-16                        2.220446e-16   \n",
      "4                        2.220446e-16                        2.220446e-16   \n",
      "\n",
      "   NAME_HOUSING_TYPE_With parents  OCCUPATION_TYPE_Cleaning staff  \\\n",
      "0                    2.220446e-16                    2.220446e-16   \n",
      "1                    2.220446e-16                    2.220446e-16   \n",
      "2                    2.220446e-16                    2.220446e-16   \n",
      "3                    2.220446e-16                    2.220446e-16   \n",
      "4                    2.220446e-16                    2.220446e-16   \n",
      "\n",
      "   OCCUPATION_TYPE_Cooking staff  OCCUPATION_TYPE_Core staff  \\\n",
      "0                   2.220446e-16                   -0.024318   \n",
      "1                   2.220446e-16                   -0.024318   \n",
      "2                   2.220446e-16                   -0.024318   \n",
      "3                   2.220446e-16                   -0.024318   \n",
      "4                   2.220446e-16                   -0.024318   \n",
      "\n",
      "   OCCUPATION_TYPE_Drivers  OCCUPATION_TYPE_HR staff  \\\n",
      "0                 0.024108              2.220446e-16   \n",
      "1                 0.024108              2.220446e-16   \n",
      "2                 0.024108              2.220446e-16   \n",
      "3                 0.024108              2.220446e-16   \n",
      "4                 0.024108              2.220446e-16   \n",
      "\n",
      "   OCCUPATION_TYPE_High skill tech staff  OCCUPATION_TYPE_IT staff  \\\n",
      "0                           2.220446e-16              2.220446e-16   \n",
      "1                           2.220446e-16              2.220446e-16   \n",
      "2                           2.220446e-16              2.220446e-16   \n",
      "3                           2.220446e-16              2.220446e-16   \n",
      "4                           2.220446e-16              2.220446e-16   \n",
      "\n",
      "   OCCUPATION_TYPE_Laborers  OCCUPATION_TYPE_Low-skill Laborers  \\\n",
      "0                  0.007792                        2.220446e-16   \n",
      "1                  0.007792                        2.220446e-16   \n",
      "2                 -0.007452                        2.220446e-16   \n",
      "3                  0.007792                        2.220446e-16   \n",
      "4                 -0.007452                        2.220446e-16   \n",
      "\n",
      "   OCCUPATION_TYPE_Managers  OCCUPATION_TYPE_Medicine staff  \\\n",
      "0                 -0.016089                    2.220446e-16   \n",
      "1                 -0.016089                    2.220446e-16   \n",
      "2                 -0.016089                    2.220446e-16   \n",
      "3                 -0.016089                    2.220446e-16   \n",
      "4                 -0.016089                    2.220446e-16   \n",
      "\n",
      "   OCCUPATION_TYPE_Private service staff  OCCUPATION_TYPE_Realty agents  \\\n",
      "0                           2.220446e-16                   2.220446e-16   \n",
      "1                           2.220446e-16                   2.220446e-16   \n",
      "2                           2.220446e-16                   2.220446e-16   \n",
      "3                           2.220446e-16                   2.220446e-16   \n",
      "4                           2.220446e-16                   2.220446e-16   \n",
      "\n",
      "   OCCUPATION_TYPE_Sales staff  OCCUPATION_TYPE_Secretaries  \\\n",
      "0                     0.028686                 2.220446e-16   \n",
      "1                     0.028686                 2.220446e-16   \n",
      "2                    -0.225802                 2.220446e-16   \n",
      "3                     0.028686                 2.220446e-16   \n",
      "4                     0.028686                 2.220446e-16   \n",
      "\n",
      "   OCCUPATION_TYPE_Security staff  OCCUPATION_TYPE_Waiters/barmen staff  \\\n",
      "0                    2.220446e-16                          2.220446e-16   \n",
      "1                    2.220446e-16                          2.220446e-16   \n",
      "2                    2.220446e-16                          2.220446e-16   \n",
      "3                    2.220446e-16                          2.220446e-16   \n",
      "4                    2.220446e-16                          2.220446e-16   \n",
      "\n",
      "   WEEKDAY_APPR_PROCESS_START_MONDAY  WEEKDAY_APPR_PROCESS_START_SATURDAY  \\\n",
      "0                          -0.008782                            -0.001768   \n",
      "1                          -0.008782                            -0.001768   \n",
      "2                          -0.008782                            -0.001768   \n",
      "3                          -0.008782                            -0.001768   \n",
      "4                           0.046556                            -0.001768   \n",
      "\n",
      "   WEEKDAY_APPR_PROCESS_START_SUNDAY  WEEKDAY_APPR_PROCESS_START_THURSDAY  \\\n",
      "0                          -0.000940                             0.002211   \n",
      "1                           0.016992                             0.002211   \n",
      "2                          -0.000940                             0.002211   \n",
      "3                          -0.000940                            -0.011136   \n",
      "4                          -0.000940                             0.002211   \n",
      "\n",
      "   WEEKDAY_APPR_PROCESS_START_TUESDAY  WEEKDAY_APPR_PROCESS_START_WEDNESDAY  \\\n",
      "0                            0.003979                              0.005270   \n",
      "1                            0.003979                              0.005270   \n",
      "2                            0.003979                             -0.025415   \n",
      "3                            0.003979                              0.005270   \n",
      "4                            0.003979                              0.005270   \n",
      "\n",
      "   ORGANIZATION_TYPE_Agriculture  ORGANIZATION_TYPE_Bank  \\\n",
      "0                   2.220446e-16            2.220446e-16   \n",
      "1                   2.220446e-16            2.220446e-16   \n",
      "2                   2.220446e-16            2.220446e-16   \n",
      "3                   2.220446e-16            2.220446e-16   \n",
      "4                   2.220446e-16            2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Business Entity Type 1  \\\n",
      "0                              2.220446e-16   \n",
      "1                              2.220446e-16   \n",
      "2                              2.220446e-16   \n",
      "3                              2.220446e-16   \n",
      "4                              2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Business Entity Type 2  \\\n",
      "0                              2.220446e-16   \n",
      "1                              2.220446e-16   \n",
      "2                              2.220446e-16   \n",
      "3                              2.220446e-16   \n",
      "4                              2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Business Entity Type 3  ORGANIZATION_TYPE_Cleaning  \\\n",
      "0                                  0.049763                2.220446e-16   \n",
      "1                                  0.049763                2.220446e-16   \n",
      "2                                 -0.163425                2.220446e-16   \n",
      "3                                  0.049763                2.220446e-16   \n",
      "4                                  0.049763                2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Construction  ORGANIZATION_TYPE_Culture  \\\n",
      "0                    2.220446e-16               2.220446e-16   \n",
      "1                    2.220446e-16               2.220446e-16   \n",
      "2                    2.220446e-16               2.220446e-16   \n",
      "3                    2.220446e-16               2.220446e-16   \n",
      "4                    2.220446e-16               2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Electricity  ORGANIZATION_TYPE_Emergency  \\\n",
      "0                   2.220446e-16                 2.220446e-16   \n",
      "1                   2.220446e-16                 2.220446e-16   \n",
      "2                   2.220446e-16                 2.220446e-16   \n",
      "3                   2.220446e-16                 2.220446e-16   \n",
      "4                   2.220446e-16                 2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Government  ORGANIZATION_TYPE_Hotel  \\\n",
      "0                  2.220446e-16             2.220446e-16   \n",
      "1                  2.220446e-16             2.220446e-16   \n",
      "2                  2.220446e-16             2.220446e-16   \n",
      "3                  2.220446e-16             2.220446e-16   \n",
      "4                  2.220446e-16             2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Housing  ORGANIZATION_TYPE_Industry: type 1  \\\n",
      "0               2.220446e-16                        2.220446e-16   \n",
      "1               2.220446e-16                        2.220446e-16   \n",
      "2               2.220446e-16                        2.220446e-16   \n",
      "3               2.220446e-16                        2.220446e-16   \n",
      "4               2.220446e-16                        2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Industry: type 10  ORGANIZATION_TYPE_Industry: type 11  \\\n",
      "0                         2.220446e-16                         2.220446e-16   \n",
      "1                         2.220446e-16                         2.220446e-16   \n",
      "2                         2.220446e-16                         2.220446e-16   \n",
      "3                         2.220446e-16                         2.220446e-16   \n",
      "4                         2.220446e-16                         2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Industry: type 12  ORGANIZATION_TYPE_Industry: type 13  \\\n",
      "0                         2.220446e-16                         2.220446e-16   \n",
      "1                         2.220446e-16                         2.220446e-16   \n",
      "2                         2.220446e-16                         2.220446e-16   \n",
      "3                         2.220446e-16                         2.220446e-16   \n",
      "4                         2.220446e-16                         2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Industry: type 2  ORGANIZATION_TYPE_Industry: type 3  \\\n",
      "0                        2.220446e-16                        2.220446e-16   \n",
      "1                        2.220446e-16                        2.220446e-16   \n",
      "2                        2.220446e-16                        2.220446e-16   \n",
      "3                        2.220446e-16                        2.220446e-16   \n",
      "4                        2.220446e-16                        2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Industry: type 4  ORGANIZATION_TYPE_Industry: type 5  \\\n",
      "0                        2.220446e-16                        2.220446e-16   \n",
      "1                        2.220446e-16                        2.220446e-16   \n",
      "2                        2.220446e-16                        2.220446e-16   \n",
      "3                        2.220446e-16                        2.220446e-16   \n",
      "4                        2.220446e-16                        2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Industry: type 6  ORGANIZATION_TYPE_Industry: type 7  \\\n",
      "0                        2.220446e-16                        2.220446e-16   \n",
      "1                        2.220446e-16                        2.220446e-16   \n",
      "2                        2.220446e-16                        2.220446e-16   \n",
      "3                        2.220446e-16                        2.220446e-16   \n",
      "4                        2.220446e-16                        2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Industry: type 8  ORGANIZATION_TYPE_Industry: type 9  \\\n",
      "0                        2.220446e-16                        2.220446e-16   \n",
      "1                        2.220446e-16                        2.220446e-16   \n",
      "2                        2.220446e-16                        2.220446e-16   \n",
      "3                        2.220446e-16                        2.220446e-16   \n",
      "4                        2.220446e-16                        2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Insurance  ORGANIZATION_TYPE_Kindergarten  \\\n",
      "0                 2.220446e-16                    2.220446e-16   \n",
      "1                 2.220446e-16                    2.220446e-16   \n",
      "2                 2.220446e-16                    2.220446e-16   \n",
      "3                 2.220446e-16                    2.220446e-16   \n",
      "4                 2.220446e-16                    2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Legal Services  ORGANIZATION_TYPE_Medicine  \\\n",
      "0                      2.220446e-16                2.220446e-16   \n",
      "1                      2.220446e-16                2.220446e-16   \n",
      "2                      2.220446e-16                2.220446e-16   \n",
      "3                      2.220446e-16                2.220446e-16   \n",
      "4                      2.220446e-16                2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Military  ORGANIZATION_TYPE_Mobile  \\\n",
      "0                2.220446e-16              2.220446e-16   \n",
      "1                2.220446e-16              2.220446e-16   \n",
      "2                2.220446e-16              2.220446e-16   \n",
      "3                2.220446e-16              2.220446e-16   \n",
      "4                2.220446e-16              2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Other  ORGANIZATION_TYPE_Police  \\\n",
      "0                -0.003041              2.220446e-16   \n",
      "1                -0.003041              2.220446e-16   \n",
      "2                -0.003041              2.220446e-16   \n",
      "3                -0.003041              2.220446e-16   \n",
      "4                -0.003041              2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Postal  ORGANIZATION_TYPE_Realtor  \\\n",
      "0              2.220446e-16               2.220446e-16   \n",
      "1              2.220446e-16               2.220446e-16   \n",
      "2              2.220446e-16               2.220446e-16   \n",
      "3              2.220446e-16               2.220446e-16   \n",
      "4              2.220446e-16               2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Religion  ORGANIZATION_TYPE_Restaurant  \\\n",
      "0                2.220446e-16                  2.220446e-16   \n",
      "1                2.220446e-16                  2.220446e-16   \n",
      "2                2.220446e-16                  2.220446e-16   \n",
      "3                2.220446e-16                  2.220446e-16   \n",
      "4                2.220446e-16                  2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_School  ORGANIZATION_TYPE_Security  \\\n",
      "0              2.220446e-16                2.220446e-16   \n",
      "1              2.220446e-16                2.220446e-16   \n",
      "2              2.220446e-16                2.220446e-16   \n",
      "3              2.220446e-16                2.220446e-16   \n",
      "4              2.220446e-16                2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Security Ministries  ORGANIZATION_TYPE_Self-employed  \\\n",
      "0                           2.220446e-16                         0.037450   \n",
      "1                           2.220446e-16                         0.037450   \n",
      "2                           2.220446e-16                         0.037450   \n",
      "3                           2.220446e-16                         0.037450   \n",
      "4                           2.220446e-16                        -0.241263   \n",
      "\n",
      "   ORGANIZATION_TYPE_Services  ORGANIZATION_TYPE_Telecom  \\\n",
      "0                2.220446e-16               2.220446e-16   \n",
      "1                2.220446e-16               2.220446e-16   \n",
      "2                2.220446e-16               2.220446e-16   \n",
      "3                2.220446e-16               2.220446e-16   \n",
      "4                2.220446e-16               2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Trade: type 1  ORGANIZATION_TYPE_Trade: type 2  \\\n",
      "0                     2.220446e-16                     2.220446e-16   \n",
      "1                     2.220446e-16                     2.220446e-16   \n",
      "2                     2.220446e-16                     2.220446e-16   \n",
      "3                     2.220446e-16                     2.220446e-16   \n",
      "4                     2.220446e-16                     2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Trade: type 3  ORGANIZATION_TYPE_Trade: type 4  \\\n",
      "0                     2.220446e-16                     2.220446e-16   \n",
      "1                     2.220446e-16                     2.220446e-16   \n",
      "2                     2.220446e-16                     2.220446e-16   \n",
      "3                     2.220446e-16                     2.220446e-16   \n",
      "4                     2.220446e-16                     2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Trade: type 5  ORGANIZATION_TYPE_Trade: type 6  \\\n",
      "0                     2.220446e-16                     2.220446e-16   \n",
      "1                     2.220446e-16                     2.220446e-16   \n",
      "2                     2.220446e-16                     2.220446e-16   \n",
      "3                     2.220446e-16                     2.220446e-16   \n",
      "4                     2.220446e-16                     2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Trade: type 7  ORGANIZATION_TYPE_Transport: type 1  \\\n",
      "0                     2.220446e-16                         2.220446e-16   \n",
      "1                     2.220446e-16                         2.220446e-16   \n",
      "2                     2.220446e-16                         2.220446e-16   \n",
      "3                     2.220446e-16                         2.220446e-16   \n",
      "4                     2.220446e-16                         2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Transport: type 2  ORGANIZATION_TYPE_Transport: type 3  \\\n",
      "0                         2.220446e-16                         2.220446e-16   \n",
      "1                         2.220446e-16                         2.220446e-16   \n",
      "2                         2.220446e-16                         2.220446e-16   \n",
      "3                         2.220446e-16                         2.220446e-16   \n",
      "4                         2.220446e-16                         2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_Transport: type 4  ORGANIZATION_TYPE_University  \\\n",
      "0                         2.220446e-16                  2.220446e-16   \n",
      "1                         2.220446e-16                  2.220446e-16   \n",
      "2                         2.220446e-16                  2.220446e-16   \n",
      "3                         2.220446e-16                  2.220446e-16   \n",
      "4                         2.220446e-16                  2.220446e-16   \n",
      "\n",
      "   ORGANIZATION_TYPE_XNA  FONDKAPREMONT_MODE_org spec account  \\\n",
      "0               0.434787                         2.220446e-16   \n",
      "1               0.434787                         2.220446e-16   \n",
      "2              -0.076478                         2.220446e-16   \n",
      "3              -0.076478                         2.220446e-16   \n",
      "4              -0.076478                         2.220446e-16   \n",
      "\n",
      "   FONDKAPREMONT_MODE_reg oper account  \\\n",
      "0                            -0.015164   \n",
      "1                            -0.015164   \n",
      "2                            -0.015164   \n",
      "3                             0.197983   \n",
      "4                            -0.015164   \n",
      "\n",
      "   FONDKAPREMONT_MODE_reg oper spec account  HOUSETYPE_MODE_specific housing  \\\n",
      "0                              2.220446e-16                     2.220446e-16   \n",
      "1                              2.220446e-16                     2.220446e-16   \n",
      "2                              2.220446e-16                     2.220446e-16   \n",
      "3                              2.220446e-16                     2.220446e-16   \n",
      "4                              2.220446e-16                     2.220446e-16   \n",
      "\n",
      "   HOUSETYPE_MODE_terraced house  WALLSMATERIAL_MODE_Mixed  \\\n",
      "0                   2.220446e-16              2.220446e-16   \n",
      "1                   2.220446e-16              2.220446e-16   \n",
      "2                   2.220446e-16              2.220446e-16   \n",
      "3                   2.220446e-16              2.220446e-16   \n",
      "4                   2.220446e-16              2.220446e-16   \n",
      "\n",
      "   WALLSMATERIAL_MODE_Monolithic  WALLSMATERIAL_MODE_Others  \\\n",
      "0                   2.220446e-16               2.220446e-16   \n",
      "1                   2.220446e-16               2.220446e-16   \n",
      "2                   2.220446e-16               2.220446e-16   \n",
      "3                   2.220446e-16               2.220446e-16   \n",
      "4                   2.220446e-16               2.220446e-16   \n",
      "\n",
      "   WALLSMATERIAL_MODE_Panel  WALLSMATERIAL_MODE_Stone, brick  \\\n",
      "0                  0.056931                         0.056209   \n",
      "1                 -0.020898                        -0.014431   \n",
      "2                 -0.020898                        -0.014431   \n",
      "3                 -0.020898                        -0.014431   \n",
      "4                 -0.020898                        -0.014431   \n",
      "\n",
      "   WALLSMATERIAL_MODE_Wooden  EMERGENCYSTATE_MODE_Yes  \n",
      "0               2.220446e-16             2.220446e-16  \n",
      "1               2.220446e-16             2.220446e-16  \n",
      "2               2.220446e-16             2.220446e-16  \n",
      "3               2.220446e-16             2.220446e-16  \n",
      "4               2.220446e-16             2.220446e-16  \n"
     ]
    }
   ],
   "source": [
    "if VAR_BINNING == True:\n",
    "\n",
    "  pd.set_option('display.max_rows', None)  # Show all rows\n",
    "  pd.set_option('display.max_columns', None)\n",
    "  print(X_train_binned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "nfI_2mYStyOz",
   "metadata": {
    "id": "nfI_2mYStyOz"
   },
   "outputs": [],
   "source": [
    "if VAR_BINNING == True:\n",
    "\n",
    "  with open(f\"{results_path}X_train_binned_head.txt\", 'w') as f:\n",
    "      f.write(str(cap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C8CTtrvKAv0G",
   "metadata": {
    "id": "C8CTtrvKAv0G"
   },
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "Eo654GcKjASB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eo654GcKjASB",
    "outputId": "db3ada70-935b-4652-b5d8-2795025a64cf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cuda (from versions: none)\n",
      "ERROR: No matching distribution found for cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Using cached shap-0.41.0.tar.gz (380 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (1.24.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (1.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (1.5.3)\n",
      "Collecting tqdm>4.25.0 (from shap)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shap) (23.0)\n",
      "Collecting slicer==0.0.7 (from shap)\n",
      "  Using cached slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Collecting numba (from shap)\n",
      "  Using cached numba-0.57.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "Collecting cloudpickle (from shap)\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>4.25.0->shap) (0.4.6)\n",
      "Collecting llvmlite<0.41,>=0.40.0dev0 (from numba->shap)\n",
      "  Using cached llvmlite-0.40.1rc1-cp311-cp311-win_amd64.whl (27.7 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->shap) (2022.7.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->shap) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->shap) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
      "Building wheels for collected packages: shap\n",
      "  Building wheel for shap (pyproject.toml): started\n",
      "  Building wheel for shap (pyproject.toml): finished with status 'error'\n",
      "Failed to build shap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for shap (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [119 lines of output]\n",
      "  The nvcc binary could not be located in your $PATH. Either  add it to your path, or set $CUDAHOME to enable CUDA\n",
      "  Error building cuda module: TypeError('cannot unpack non-iterable NoneType object')\n",
      "  WARNING: Could not compile cuda extensions\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-311\n",
      "  creating build\\lib.win-amd64-cpython-311\\shap\n",
      "  copying shap\\datasets.py -> build\\lib.win-amd64-cpython-311\\shap\n",
      "  copying shap\\links.py -> build\\lib.win-amd64-cpython-311\\shap\n",
      "  copying shap\\_explanation.py -> build\\lib.win-amd64-cpython-311\\shap\n",
      "  copying shap\\_serializable.py -> build\\lib.win-amd64-cpython-311\\shap\n",
      "  copying shap\\__init__.py -> build\\lib.win-amd64-cpython-311\\shap\n",
      "  creating build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\mimic.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\pytree.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\tf_utils.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\_additive.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\_exact.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\_explainer.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\_gpu_tree.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\_gradient.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\_kernel.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\_linear.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\_partition.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\_permutation.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\_sampling.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\_tree.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  copying shap\\explainers\\__init__.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\n",
      "  creating build\\lib.win-amd64-cpython-311\\shap\\explainers\\other\n",
      "  copying shap\\explainers\\other\\_coefficent.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\\other\n",
      "  copying shap\\explainers\\other\\_lime.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\\other\n",
      "  copying shap\\explainers\\other\\_maple.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\\other\n",
      "  copying shap\\explainers\\other\\_random.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\\other\n",
      "  copying shap\\explainers\\other\\_treegain.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\\other\n",
      "  copying shap\\explainers\\other\\__init__.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\\other\n",
      "  creating build\\lib.win-amd64-cpython-311\\shap\\explainers\\_deep\n",
      "  copying shap\\explainers\\_deep\\deep_pytorch.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\\_deep\n",
      "  copying shap\\explainers\\_deep\\deep_tf.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\\_deep\n",
      "  copying shap\\explainers\\_deep\\__init__.py -> build\\lib.win-amd64-cpython-311\\shap\\explainers\\_deep\n",
      "  creating build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_bar.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_beeswarm.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_benchmark.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_decision.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_embedding.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_force.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_force_matplotlib.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_group_difference.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_heatmap.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_image.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_labels.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_monitoring.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_partial_dependence.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_scatter.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_text.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_utils.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_violin.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\_waterfall.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  copying shap\\plots\\__init__.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\n",
      "  creating build\\lib.win-amd64-cpython-311\\shap\\plots\\colors\n",
      "  copying shap\\plots\\colors\\_colorconv.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\\colors\n",
      "  copying shap\\plots\\colors\\_colors.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\\colors\n",
      "  copying shap\\plots\\colors\\__init__.py -> build\\lib.win-amd64-cpython-311\\shap\\plots\\colors\n",
      "  creating build\\lib.win-amd64-cpython-311\\shap\\benchmark\n",
      "  copying shap\\benchmark\\experiments.py -> build\\lib.win-amd64-cpython-311\\shap\\benchmark\n",
      "  copying shap\\benchmark\\framework.py -> build\\lib.win-amd64-cpython-311\\shap\\benchmark\n",
      "  copying shap\\benchmark\\measures.py -> build\\lib.win-amd64-cpython-311\\shap\\benchmark\n",
      "  copying shap\\benchmark\\methods.py -> build\\lib.win-amd64-cpython-311\\shap\\benchmark\n",
      "  copying shap\\benchmark\\metrics.py -> build\\lib.win-amd64-cpython-311\\shap\\benchmark\n",
      "  copying shap\\benchmark\\models.py -> build\\lib.win-amd64-cpython-311\\shap\\benchmark\n",
      "  copying shap\\benchmark\\plots.py -> build\\lib.win-amd64-cpython-311\\shap\\benchmark\n",
      "  copying shap\\benchmark\\_compute.py -> build\\lib.win-amd64-cpython-311\\shap\\benchmark\n",
      "  copying shap\\benchmark\\_explanation_error.py -> build\\lib.win-amd64-cpython-311\\shap\\benchmark\n",
      "  copying shap\\benchmark\\_result.py -> build\\lib.win-amd64-cpython-311\\shap\\benchmark\n",
      "  copying shap\\benchmark\\_sequential.py -> build\\lib.win-amd64-cpython-311\\shap\\benchmark\n",
      "  copying shap\\benchmark\\__init__.py -> build\\lib.win-amd64-cpython-311\\shap\\benchmark\n",
      "  creating build\\lib.win-amd64-cpython-311\\shap\\maskers\n",
      "  copying shap\\maskers\\_composite.py -> build\\lib.win-amd64-cpython-311\\shap\\maskers\n",
      "  copying shap\\maskers\\_fixed.py -> build\\lib.win-amd64-cpython-311\\shap\\maskers\n",
      "  copying shap\\maskers\\_fixed_composite.py -> build\\lib.win-amd64-cpython-311\\shap\\maskers\n",
      "  copying shap\\maskers\\_image.py -> build\\lib.win-amd64-cpython-311\\shap\\maskers\n",
      "  copying shap\\maskers\\_masker.py -> build\\lib.win-amd64-cpython-311\\shap\\maskers\n",
      "  copying shap\\maskers\\_output_composite.py -> build\\lib.win-amd64-cpython-311\\shap\\maskers\n",
      "  copying shap\\maskers\\_tabular.py -> build\\lib.win-amd64-cpython-311\\shap\\maskers\n",
      "  copying shap\\maskers\\_text.py -> build\\lib.win-amd64-cpython-311\\shap\\maskers\n",
      "  copying shap\\maskers\\__init__.py -> build\\lib.win-amd64-cpython-311\\shap\\maskers\n",
      "  creating build\\lib.win-amd64-cpython-311\\shap\\utils\n",
      "  copying shap\\utils\\image.py -> build\\lib.win-amd64-cpython-311\\shap\\utils\n",
      "  copying shap\\utils\\transformers.py -> build\\lib.win-amd64-cpython-311\\shap\\utils\n",
      "  copying shap\\utils\\_clustering.py -> build\\lib.win-amd64-cpython-311\\shap\\utils\n",
      "  copying shap\\utils\\_exceptions.py -> build\\lib.win-amd64-cpython-311\\shap\\utils\n",
      "  copying shap\\utils\\_general.py -> build\\lib.win-amd64-cpython-311\\shap\\utils\n",
      "  copying shap\\utils\\_keras.py -> build\\lib.win-amd64-cpython-311\\shap\\utils\n",
      "  copying shap\\utils\\_legacy.py -> build\\lib.win-amd64-cpython-311\\shap\\utils\n",
      "  copying shap\\utils\\_masked_model.py -> build\\lib.win-amd64-cpython-311\\shap\\utils\n",
      "  copying shap\\utils\\_show_progress.py -> build\\lib.win-amd64-cpython-311\\shap\\utils\n",
      "  copying shap\\utils\\__init__.py -> build\\lib.win-amd64-cpython-311\\shap\\utils\n",
      "  creating build\\lib.win-amd64-cpython-311\\shap\\actions\n",
      "  copying shap\\actions\\_action.py -> build\\lib.win-amd64-cpython-311\\shap\\actions\n",
      "  copying shap\\actions\\_optimizer.py -> build\\lib.win-amd64-cpython-311\\shap\\actions\n",
      "  copying shap\\actions\\__init__.py -> build\\lib.win-amd64-cpython-311\\shap\\actions\n",
      "  creating build\\lib.win-amd64-cpython-311\\shap\\models\n",
      "  copying shap\\models\\_model.py -> build\\lib.win-amd64-cpython-311\\shap\\models\n",
      "  copying shap\\models\\_teacher_forcing.py -> build\\lib.win-amd64-cpython-311\\shap\\models\n",
      "  copying shap\\models\\_text_generation.py -> build\\lib.win-amd64-cpython-311\\shap\\models\n",
      "  copying shap\\models\\_topk_lm.py -> build\\lib.win-amd64-cpython-311\\shap\\models\n",
      "  copying shap\\models\\_transformers_pipeline.py -> build\\lib.win-amd64-cpython-311\\shap\\models\n",
      "  copying shap\\models\\__init__.py -> build\\lib.win-amd64-cpython-311\\shap\\models\n",
      "  creating build\\lib.win-amd64-cpython-311\\shap\\plots\\resources\n",
      "  copying shap\\plots\\resources\\bundle.js -> build\\lib.win-amd64-cpython-311\\shap\\plots\\resources\n",
      "  copying shap\\plots\\resources\\logoSmallGray.png -> build\\lib.win-amd64-cpython-311\\shap\\plots\\resources\n",
      "  creating build\\lib.win-amd64-cpython-311\\shap\\cext\n",
      "  copying shap\\cext\\tree_shap.h -> build\\lib.win-amd64-cpython-311\\shap\\cext\n",
      "  running build_ext\n",
      "  numpy.get_include() C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-mf63ppe9\\overlay\\Lib\\site-packages\\numpy\\core\\include\n",
      "  building 'shap._cext' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for shap\n",
      "ERROR: Could not build wheels for shap, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-plot in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-plot) (3.6.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-plot) (1.2.2)\n",
      "Requirement already satisfied: scipy>=0.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-plot) (1.10.0)\n",
      "Requirement already satisfied: joblib>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-plot) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.18->scikit-plot) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install cuda\n",
    "!pip install shap\n",
    "!pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zR6x8g-byJT5",
   "metadata": {
    "id": "zR6x8g-byJT5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "import scikitplot as skplt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report,  confusion_matrix, ConfusionMatrixDisplay, make_scorer, PrecisionRecallDisplay, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RoKm03RDxAHj",
   "metadata": {
    "id": "RoKm03RDxAHj"
   },
   "outputs": [],
   "source": [
    "# Helper function that calculates Confusion Matrix, Precision-Recall Curve and ROC and plots them\n",
    "def plot_cm_pr_roc(y_test, y_pred, title):\n",
    "  fig = plt.figure(figsize=(12, 8))\n",
    "  ax1 = fig.add_subplot(2, 2, 1)\n",
    "  ax2 = fig.add_subplot(2, 2, 2)\n",
    "  ax3 = fig.add_subplot(2, 2, 3)\n",
    "\n",
    "  ax1.set_title('Confusion Matrix')\n",
    "  disp_cm = ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax1)\n",
    "\n",
    "  ax2.set_title('Precision-Recall Curve')\n",
    "  disp_pr = PrecisionRecallDisplay.from_predictions(y_test, y_pred, ax=ax2)\n",
    "\n",
    "  ax3.set_title('Receiver Operating Characteristic (ROC)')\n",
    "  fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "  roc_auc = auc(fpr, tpr)\n",
    "  ax3.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "  ax3.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "  ax3.set_xlim([0.0, 1.0])\n",
    "  ax3.set_ylim([0.0, 1.05])\n",
    "  ax3.set_xlabel('False Positive Rate')\n",
    "  ax3.set_ylabel('True Positive Rate')\n",
    "  ax3.legend(loc=\"lower right\")\n",
    "\n",
    "  fig.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "  fig.suptitle(title.upper(), fontsize=16)\n",
    "\n",
    "  plt.savefig(f\"{results_path}{title}.png\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Awlo7AdYpFxO",
   "metadata": {
    "id": "Awlo7AdYpFxO"
   },
   "outputs": [],
   "source": [
    "def plot_calibration_curve_and_ks(y_test, y_prob, title):\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(y_test.values, y_prob[:,1], n_bins=10)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    # Plotting the calibration curve\n",
    "    ax1.plot(mean_predicted_value, fraction_of_positives, 's-', label='Calibration Curve')\n",
    "    ax1.plot([0, 1], [0, 1], '--', color='gray', label='Perfectly Calibrated')\n",
    "    ax1.set_xlabel('Mean Predicted Value')\n",
    "    ax1.set_ylabel('Fraction of Positives')\n",
    "    ax1.set_title('Calibration Plot')\n",
    "    ax1.legend(loc='lower right')\n",
    "\n",
    "    skplt.metrics.plot_ks_statistic(y_test, y_prob, ax=ax2)\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.4)\n",
    "    fig.suptitle(title.upper(), fontsize=16)\n",
    "\n",
    "    plt.savefig(f\"{results_path}{title}.png\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X0z1B9QBAip3",
   "metadata": {
    "id": "X0z1B9QBAip3"
   },
   "outputs": [],
   "source": [
    "def evaluate_ks_and_roc_auc(y_test, y_prob):\n",
    "    # Unite both visions to be able to filter\n",
    "    df = pd.DataFrame()\n",
    "    df['real'] = y_test\n",
    "    df['proba'] = y_prob[:, 1]\n",
    "    \n",
    "    # Recover each class\n",
    "    class0 = df[df['real'] == 0]\n",
    "    class1 = df[df['real'] == 1]\n",
    "    \n",
    "    ks = ks_2samp(class0['proba'], class1['proba'])\n",
    "    roc_auc = roc_auc_score(df['real'] , df['proba'])\n",
    "    \n",
    "    print(f\"KS: {ks.statistic:.4f} (p-value: {ks.pvalue:.3e})\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    return ks.statistic, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xEuvKiMqYbMD",
   "metadata": {
    "id": "xEuvKiMqYbMD"
   },
   "outputs": [],
   "source": [
    "def gini_normalized(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Simple normalized Gini based on Scikit-Learn's roc_auc_score\n",
    "    copied from here: https://www.kaggle.com/code/mathcass/tips-for-using-scikit-learn-for-evaluation\n",
    "    \"\"\"\n",
    "    gini = lambda t, p: 2 * roc_auc_score(t, p) - 1\n",
    "    return gini(y_test, y_pred) / gini(y_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gy7C8gnKrkv0",
   "metadata": {
    "id": "gy7C8gnKrkv0"
   },
   "outputs": [],
   "source": [
    "# Create models\n",
    "lr_model = LogisticRegression()\n",
    "rf_model = RandomForestClassifier()\n",
    "xgb_model = XGBClassifier()\n",
    "nb_model = GaussianNB()\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "names = ['logistic regression', 'gaussian naive bayes', 'random forest', 'XGB', 'decision tree']\n",
    "classifiers = [lr_model,\n",
    "               nb_model,\n",
    "               rf_model,\n",
    "               xgb_model,\n",
    "               dt_model]\n",
    "selected_training_features_per_model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FcRbvIsdpyve",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FcRbvIsdpyve",
    "outputId": "7df6e214-bd49-4a11-f7f1-4cdba7c6da31"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%%capture cap --no-stderr\n",
    "del cap\n",
    "\n",
    "# Select Top 20 Features for each model, took 24 min for smallest dataset\n",
    "def select_top_features(model, X_train, y_train, n_features):\n",
    "    sfs = SequentialFeatureSelector(estimator=model, scoring='roc_auc', n_features_to_select=n_features)\n",
    "    sfs.fit(X_train, y_train)\n",
    "    selected_features = X_train.columns[sfs.get_support()].tolist()\n",
    "    return selected_features\n",
    "\n",
    "\n",
    "if VAR_BINNING == True:\n",
    "  for name, clf in zip(names, classifiers):\n",
    "      selected_features = select_top_features(clf, X_train_binned, y_train, 20)\n",
    "      selected_training_features_per_model.append(selected_features)\n",
    "\n",
    "      print(f\"Selected Features ({name}):\")\n",
    "      print(selected_features)\n",
    "\n",
    "else:\n",
    "  for name, clf in zip(names, classifiers):\n",
    "      selected_features = select_top_features(clf, X_train, y_train, 20)\n",
    "      selected_training_features_per_model.append(selected_features)\n",
    "\n",
    "      print(f\"Selected Features ({name}):\")\n",
    "      print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RpOzNplvvMAW",
   "metadata": {
    "id": "RpOzNplvvMAW"
   },
   "outputs": [],
   "source": [
    "with open(f\"{results_path}selected_features.txt\", 'w') as f:\n",
    "    f.write(str(cap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PmQ21nMLpV40",
   "metadata": {
    "id": "PmQ21nMLpV40"
   },
   "outputs": [],
   "source": [
    "# For dataset 2:\n",
    "#selected_training_features_per_model = [\n",
    "#    ['LIMIT_BAL', 'PAY_0', 'PAY_5', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'worst_status', 'mean_status', 'ID', 'SEX_2', 'EDUCATION_2', 'EDUCATION_4', 'EDUCATION_5', 'EDUCATION_6', 'MARRIAGE_2', 'MARRIAGE_3'],\n",
    "#    ['LIMIT_BAL', 'PAY_0', 'BILL_AMT1', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT6', 'worst_status', 'mean_status', 'ID', 'SEX_2', 'EDUCATION_2', 'EDUCATION_3', 'EDUCATION_4', 'EDUCATION_5', 'EDUCATION_6', 'MARRIAGE_1', 'MARRIAGE_2', 'MARRIAGE_3'],\n",
    "#    ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'worst_status', 'money_difference', 'EDUCATION_3', 'EDUCATION_4', 'EDUCATION_5', 'EDUCATION_6', 'MARRIAGE_1', 'MARRIAGE_2', 'MARRIAGE_3'],\n",
    "#    ['LIMIT_BAL', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_5', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT6', 'PAY_AMT1', 'worst_status', 'mean_status', 'money_difference', 'SEX_2', 'EDUCATION_1', 'EDUCATION_4', 'EDUCATION_5', 'EDUCATION_6', 'MARRIAGE_1', 'MARRIAGE_2', 'MARRIAGE_3'],\n",
    "#    ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_5', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'worst_status', 'money_difference', 'SEX_2', 'EDUCATION_1', 'EDUCATION_2', 'EDUCATION_3', 'EDUCATION_4', 'EDUCATION_5', 'EDUCATION_6', 'MARRIAGE_1', 'MARRIAGE_2', 'MARRIAGE_3']\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yW_7zqG7rM8E",
   "metadata": {
    "id": "yW_7zqG7rM8E"
   },
   "outputs": [],
   "source": [
    "# Train each model with the above selected features\n",
    "if VAR_BINNING == True:\n",
    "  for name, clf, selected_features in zip(names, classifiers, selected_training_features_per_model):\n",
    "      clf.fit(X_train_binned[selected_features], y_train)\n",
    "      \n",
    "else:\n",
    "   for name, clf, selected_features in zip(names, classifiers, selected_training_features_per_model):\n",
    "      clf.fit(X_train[selected_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F1hUkyxCuCsm",
   "metadata": {
    "id": "F1hUkyxCuCsm"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%%capture cap --no-stderr\n",
    "del cap\n",
    "\n",
    "if VAR_BINNING == True:\n",
    "  # make binary classification without probabilities on test set for first version of trained models\n",
    "  for name, clf, selected_features in zip(names, classifiers, selected_training_features_per_model):\n",
    "      y_pred = clf.predict(X_test_binned[selected_features])\n",
    "      plot_title = name + \" binary training\"\n",
    "      plot_cm_pr_roc(y_test, y_pred, plot_title)\n",
    "      print(classification_report(y_test, y_pred, target_names=['Good Risk Performance', 'Bad Risk Performance']))\n",
    "      print(f\"Gini Coefficient: {gini_normalized(y_test, y_pred)}\")\n",
    "      \n",
    "      conf_m = confusion_matrix(y_test, y_pred).T\n",
    "      print(conf_m)\n",
    "      print(np.sum(conf_m * cost_m))\n",
    "\n",
    "else:\n",
    "  for name, clf, selected_features in zip(names, classifiers, selected_training_features_per_model):\n",
    "      y_pred = clf.predict(X_test[selected_features])\n",
    "      plot_title = name + \" binary training\"\n",
    "      plot_cm_pr_roc(y_test, y_pred, plot_title)\n",
    "      print(classification_report(y_test, y_pred, target_names=['Good Risk Performance', 'Bad Risk Performance']))\n",
    "      print(f\"Gini Coefficient: {gini_normalized(y_test, y_pred)}\")\n",
    "      \n",
    "      conf_m = confusion_matrix(y_test, y_pred).T\n",
    "      print(conf_m)\n",
    "      print(np.sum(conf_m * cost_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fFhFyRv9wpOi",
   "metadata": {
    "id": "fFhFyRv9wpOi"
   },
   "outputs": [],
   "source": [
    "with open(f\"{results_path}training_results.txt\", 'w') as f:\n",
    "    f.write(str(cap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4Sw_o5ckroEJ",
   "metadata": {
    "id": "4Sw_o5ckroEJ"
   },
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Except for the Naive Bayes model we use a gridsearch approach to find hyperparameters for all our used models:\n",
    "- Decision tree\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Random forest\n",
    "- XGBoost\n",
    "\n",
    "Code snippets used from: https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wPF-jrGar9HE",
   "metadata": {
    "id": "wPF-jrGar9HE"
   },
   "outputs": [],
   "source": [
    "# create gini scorer that can be used for validation scoring\n",
    "gini_score = make_scorer(gini_normalized, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Re_azfHQqH3l",
   "metadata": {
    "id": "Re_azfHQqH3l"
   },
   "source": [
    "## Logistic Regression - Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KZdxclxuwnTI",
   "metadata": {
    "id": "KZdxclxuwnTI"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%%capture cap --no-stderr\n",
    "del cap\n",
    "\n",
    "# define models and parameters\n",
    "model = lr_model\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, scoring=gini_score, cv=5)\n",
    "\n",
    "if VAR_BINNING == True:\n",
    "  grid_result_lr = grid_search.fit(X_val_binned, y_validate)\n",
    "\n",
    "else:\n",
    "  grid_result_lr = grid_search.fit(X_validate, y_validate)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result_lr.best_score_, grid_result_lr.best_params_))\n",
    "means = grid_result_lr.cv_results_['mean_test_score']\n",
    "stds = grid_result_lr.cv_results_['std_test_score']\n",
    "params = grid_result_lr.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enNMhT7kDAQu",
   "metadata": {
    "id": "enNMhT7kDAQu"
   },
   "outputs": [],
   "source": [
    "with open(f\"{results_path}logistic_regression_hp.txt\", 'w') as f:\n",
    "    f.write(str(cap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aJ7klgzmrdm5",
   "metadata": {
    "id": "aJ7klgzmrdm5"
   },
   "source": [
    "## Random Forest - Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KF6eB95WrcvL",
   "metadata": {
    "id": "KF6eB95WrcvL"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%%capture cap --no-stderr\n",
    "del cap\n",
    "\n",
    "# define models and parameters\n",
    "model = rf_model\n",
    "n_estimators = [10, 100, 1000]\n",
    "max_features = ['sqrt', 'log2']\n",
    "max_depth = [10, 15]\n",
    "\n",
    "# define grid search\n",
    "grid = dict(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, scoring=gini_score, cv=5)\n",
    "\n",
    "if VAR_BINNING == True:\n",
    "  grid_result_rf = grid_search.fit(X_val_binned, y_validate)\n",
    "\n",
    "else:\n",
    "  grid_result_rf = grid_search.fit(X_validate, y_validate)\n",
    "\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result_rf.best_score_, grid_result_rf.best_params_))\n",
    "means = grid_result_rf.cv_results_['mean_test_score']\n",
    "stds = grid_result_rf.cv_results_['std_test_score']\n",
    "params = grid_result_rf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18o17iQFDEor",
   "metadata": {
    "id": "18o17iQFDEor"
   },
   "outputs": [],
   "source": [
    "with open(f\"{results_path}random_forest_hp.txt\", 'w') as f:\n",
    "    f.write(str(cap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qGuNM_FgBOHW",
   "metadata": {
    "id": "qGuNM_FgBOHW"
   },
   "source": [
    "## XGBoost - Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fgDiPLA-BNih",
   "metadata": {
    "id": "fgDiPLA-BNih"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%%capture cap --no-stderr\n",
    "del cap\n",
    "\n",
    "# define models and parameters\n",
    "model = xgb_model\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'max_depth': [10, 15],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation to tune the hyperparameters\n",
    "grid_result_xgb = GridSearchCV(model, param_grid, scoring=gini_score, cv=5)\n",
    "\n",
    "if VAR_BINNING == True:\n",
    "  grid_result_xgb = grid_search.fit(X_val_binned, y_validate)\n",
    "\n",
    "else:\n",
    "  grid_result_xgb = grid_search.fit(X_validate, y_validate)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result_xgb.best_score_, grid_result_xgb.best_params_))\n",
    "means = grid_result_xgb.cv_results_['mean_test_score']\n",
    "stds = grid_result_xgb.cv_results_['std_test_score']\n",
    "params = grid_result_xgb.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OPGNAaJPDIU0",
   "metadata": {
    "id": "OPGNAaJPDIU0"
   },
   "outputs": [],
   "source": [
    "with open(f\"{results_path}xgb_hp.txt\", 'w') as f:\n",
    "    f.write(str(cap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EB0O8Lii7vn6",
   "metadata": {
    "id": "EB0O8Lii7vn6"
   },
   "source": [
    "## Decision Tree - Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LOB30TKM6knP",
   "metadata": {
    "id": "LOB30TKM6knP"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%%capture cap --no-stderr\n",
    "del cap\n",
    "\n",
    "# define models and parameters\n",
    "model = dt_model\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation to tune the hyperparameters\n",
    "grid_result_dt = GridSearchCV(model, param_grid, scoring=gini_score, cv=5)\n",
    "\n",
    "if VAR_BINNING == True:\n",
    "  grid_result_dt = grid_search.fit(X_val_binned, y_validate)\n",
    "\n",
    "else:\n",
    "  grid_result_dt = grid_search.fit(X_validate, y_validate)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result_dt.best_score_, grid_result_dt.best_params_))\n",
    "means = grid_result_dt.cv_results_['mean_test_score']\n",
    "stds = grid_result_dt.cv_results_['std_test_score']\n",
    "params = grid_result_dt.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0E1GIkjGDMdd",
   "metadata": {
    "id": "0E1GIkjGDMdd"
   },
   "outputs": [],
   "source": [
    "with open(f\"{results_path}decision_tree_hp.txt\", 'w') as f:\n",
    "    f.write(str(cap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-TsFrSoUwHwO",
   "metadata": {
    "id": "-TsFrSoUwHwO"
   },
   "outputs": [],
   "source": [
    "# Plot a pruned to depth of 5 version of the decision tree\n",
    "fig = plt.figure(figsize=(55,20))\n",
    "\n",
    "plot_tree(decision_tree=dt_model, max_depth=5, feature_names=X_train.columns, fontsize=6)\n",
    "\n",
    "plt.savefig(f'{results_path}tree_high_dpi_dataset_{dataset_number}', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mx4tP-cRlJox",
   "metadata": {
    "id": "mx4tP-cRlJox"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_model = grid_result_lr.best_estimator_\n",
    "rf_model = grid_result_rf.best_estimator_\n",
    "xgb_model = grid_result_xgb.best_estimator_\n",
    "dt_model = grid_result_dt.best_estimator_\n",
    "# nb_model wasn't tuned so it stays the same\n",
    "\n",
    "estimators = [('lr', lr_model), ('nb', nb_model), ('rf', rf_model), ('xgb', xgb_model), ('dt', dt_model)]\n",
    "\n",
    "stacking_model = StackingClassifier(estimators=estimators, stack_method='predict_proba')\n",
    "\n",
    "classifiers.append(stacking_model)\n",
    "names.append('stacking')\n",
    "\n",
    "if VAR_BINNING == True:\n",
    "  selected_training_features_per_model.append(X_train_binned.columns.tolist())\n",
    "\n",
    "else:\n",
    "  selected_training_features_per_model.append(X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EQq821ZNE2xk",
   "metadata": {
    "id": "EQq821ZNE2xk"
   },
   "outputs": [],
   "source": [
    "# fit stacking once to be able to use predict function\n",
    "if VAR_BINNING==True:\n",
    "  stacking_model.fit(X_train_binned, y_train)\n",
    "else:\n",
    "  stacking_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PYkxybbCHoMU",
   "metadata": {
    "id": "PYkxybbCHoMU"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%%capture cap --no-stderr\n",
    "del cap\n",
    "\n",
    "# make binary classification without probabilities on test set\n",
    "if VAR_BINNING == True:\n",
    "  for name, clf, selected_features in zip(names, classifiers, selected_training_features_per_model):\n",
    "      print(name)\n",
    "      y_pred = clf.predict(X_test_binned[selected_features])\n",
    "      plot_title = name + \" binary test\"\n",
    "      plot_cm_pr_roc(y_test, y_pred, plot_title)\n",
    "      print(classification_report(y_test, y_pred, target_names=['Good Risk Performance', 'Bad Risk Performance']))\n",
    "      print(f\"Gini Coefficient: {gini_normalized(y_test, y_pred)}\")\n",
    "      \n",
    "      conf_m = confusion_matrix(y_test, y_pred).T\n",
    "      print(conf_m)\n",
    "      print(np.sum(conf_m * cost_m))\n",
    "\n",
    "else:\n",
    "  for name, clf, selected_features in zip(names, classifiers, selected_training_features_per_model):\n",
    "      print(name)\n",
    "      y_pred = clf.predict(X_test[selected_features])\n",
    "      plot_title = name + \" binary test\"\n",
    "      plot_cm_pr_roc(y_test, y_pred, plot_title)\n",
    "      print(classification_report(y_test, y_pred, target_names=['Good Risk Performance', 'Bad Risk Performance']))\n",
    "      print(f\"Gini Coefficient: {gini_normalized(y_test, y_pred)}\")\n",
    "      \n",
    "      conf_m = confusion_matrix(y_test, y_pred).T\n",
    "      print(conf_m)\n",
    "      print(np.sum(conf_m * cost_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WovotniRD1Ey",
   "metadata": {
    "id": "WovotniRD1Ey"
   },
   "outputs": [],
   "source": [
    "with open(f\"{results_path}binary_classification_test.txt\", 'w') as f:\n",
    "    f.write(str(cap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sXIWg5ZMp3Fr",
   "metadata": {
    "id": "sXIWg5ZMp3Fr"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%%capture cap --no-stderr\n",
    "del cap\n",
    "\n",
    "if VAR_BINNING == True:\n",
    "  # make classification with probabilities and plot calibration plots\n",
    "  for name, clf, selected_features in zip(names, classifiers, selected_training_features_per_model):\n",
    "    print(name)\n",
    "    plot_title = name + \" probabilities test\"\n",
    "    y_prob = clf.predict_proba(X_test_binned[selected_features])\n",
    "    plot_calibration_curve_and_ks(y_test, y_prob, plot_title)\n",
    "    evaluate_ks_and_roc_auc(y_test, y_prob)\n",
    "\n",
    "else:\n",
    "  # make classification with probabilities and plot calibration plots\n",
    "  for name, clf, selected_features in zip(names, classifiers, selected_training_features_per_model):\n",
    "    print(name)\n",
    "    plot_title = name + \" probabilities test\"\n",
    "    y_prob = clf.predict_proba(X_test[selected_features])\n",
    "    plot_calibration_curve_and_ks(y_test, y_prob, plot_title)\n",
    "    evaluate_ks_and_roc_auc(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hi1S6citECxs",
   "metadata": {
    "id": "hi1S6citECxs"
   },
   "outputs": [],
   "source": [
    "with open(f\"{results_path}probability_prediction_test.txt\", 'w') as f:\n",
    "    f.write(str(cap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DmlEkShc38BT",
   "metadata": {
    "id": "DmlEkShc38BT"
   },
   "outputs": [],
   "source": [
    "# Calculate SHAP Values\n",
    "if VAR_BINNING == True:\n",
    "  for name, clf, selected_features in zip(names, classifiers, selected_training_features_per_model):\n",
    "    # for blackbox models calculate shap values\n",
    "    if name in ['random forest', 'XGB']:\n",
    "      print(name)\n",
    "      y_prob = clf.predict_proba(X_test_binned[selected_features])\n",
    "      print('Calculating SHAP values...')\n",
    "      # Fits the explainer\n",
    "      explainer = shap.Explainer(clf.predict, X_test)\n",
    "      # Calculates the SHAP values - It takes some time\n",
    "      shap_values = explainer(X_test)\n",
    "\n",
    "      shap.plots.bar(shap_values)\n",
    "\n",
    "      shap.plots.beeswarm(shap_values)\n",
    "\n",
    "else:\n",
    "  for name, clf, selected_features in zip(names, classifiers, selected_training_features_per_model):\n",
    "    # for blackbox models calculate shap values\n",
    "    if name in ['random forest', 'XGB']:\n",
    "      print(name)\n",
    "      y_prob = clf.predict_proba(X_test[selected_features])\n",
    "      print('Calculating SHAP values...')\n",
    "      # Fits the explainer\n",
    "      explainer = shap.Explainer(clf.predict, X_test)\n",
    "      # Calculates the SHAP values - It takes some time\n",
    "      shap_values = explainer(X_test)\n",
    "\n",
    "      shap.plots.bar(shap_values)\n",
    "\n",
    "      shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rs6ucbNnGKkT",
   "metadata": {
    "id": "rs6ucbNnGKkT"
   },
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
