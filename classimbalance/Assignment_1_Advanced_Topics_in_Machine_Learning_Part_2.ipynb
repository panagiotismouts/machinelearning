{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4QovMenc5RGcT99wY64Me",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panagiotismouts/machinelearning/blob/main/classimbalance/Assignment_1_Advanced_Topics_in_Machine_Learning_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 1 - Part 2\n",
        "\n",
        "\n",
        "\n",
        "Andreas Kiziridis - Erasmus Student\n",
        "\n",
        "Moutsiounas Panagiotis - 153"
      ],
      "metadata": {
        "id": "lndxvpSn4wCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part of the assignment, we will "
      ],
      "metadata": {
        "id": "tmb9zVTs4yrx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5HNDOKhE4qE8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "df = pd.read_csv(\"carclaims.csv\")\n",
        "\n",
        "#print(df[:10])\n",
        "df['FraudFound'].value_counts()\n",
        "\n",
        "X = df.iloc[:, :-1]\n",
        "\n",
        "y = df.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9rOck83FHhj",
        "outputId": "afa08a3d-a3c6-4cda-b77c-4a263700ca7e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         No\n",
              "1         No\n",
              "2         No\n",
              "3         No\n",
              "4         No\n",
              "        ... \n",
              "15415    Yes\n",
              "15416     No\n",
              "15417    Yes\n",
              "15418     No\n",
              "15419    Yes\n",
              "Name: FraudFound, Length: 15420, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_converted = X.copy()\n",
        "\n",
        "y_converted = y.copy()\n",
        "\n",
        "# Instantiate the encoder and fit on the categorical columns\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "cat_cols = X_converted.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "\n",
        "for col in cat_cols:\n",
        "    X_converted[col] = encoder.fit_transform(X_converted[col])\n",
        "\n",
        "y_converted = encoder.fit_transform(y_converted.values)\n",
        "\n",
        "print(y_converted)\n",
        "# 0 means no fraud, 1 means fraud after label encoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfKfIbS9_6bs",
        "outputId": "04c6dadb-76a4-493c-eecd-3eb8cc2469ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using the value_counts() method we can see that the dataset is very imbalanced. We proceed in using some class imbalance technics."
      ],
      "metadata": {
        "id": "8gIK2oHZ78Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_converted, y_converted, test_size=0.3, random_state=42)\n",
        "\n",
        "#training the data\n",
        "names = ['random forest', 'linear SVM', 'gaussian naïve bayes']\n",
        "\n",
        "classifiers = [RandomForestClassifier(n_estimators=150, random_state=42), \n",
        "               LinearSVC(max_iter= 2000, C=0.7), GaussianNB()]\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "  print(\" \")\n",
        "  print(name)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(classification_report(y_test, y_pred, target_names=['no fraud', 'fraud']))\n",
        "  conf_m = confusion_matrix(y_test, y_pred).T # transpose to align with slides\n",
        "  print(conf_m)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKq9M1j97wWc",
        "outputId": "aa9d17e2-4fd7-418d-fe19-b7fc7781742e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "random forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    no fraud       0.94      1.00      0.97      4341\n",
            "       fraud       1.00      0.00      0.01       285\n",
            "\n",
            "    accuracy                           0.94      4626\n",
            "   macro avg       0.97      0.50      0.49      4626\n",
            "weighted avg       0.94      0.94      0.91      4626\n",
            "\n",
            "[[4341  284]\n",
            " [   0    1]]\n",
            " \n",
            "linear SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    no fraud       0.94      1.00      0.97      4341\n",
            "       fraud       0.00      0.00      0.00       285\n",
            "\n",
            "    accuracy                           0.94      4626\n",
            "   macro avg       0.47      0.50      0.48      4626\n",
            "weighted avg       0.88      0.94      0.91      4626\n",
            "\n",
            "[[4341  285]\n",
            " [   0    0]]\n",
            " \n",
            "gaussian naïve bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    no fraud       0.94      0.96      0.95      4341\n",
            "       fraud       0.18      0.15      0.16       285\n",
            "\n",
            "    accuracy                           0.91      4626\n",
            "   macro avg       0.56      0.55      0.56      4626\n",
            "weighted avg       0.90      0.91      0.90      4626\n",
            "\n",
            "[[4151  243]\n",
            " [ 190   42]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import make_pipeline\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "from imblearn.ensemble import EasyEnsembleClassifier\n",
        "\n",
        "from imblearn.under_sampling import NearMiss\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_converted, y_converted, test_size=0.3, random_state=42, stratify=y_converted)\n",
        "\n",
        "#OVERSAMPLING using SMOTE (Synthetic Minority Over-sampling Technique)\n",
        "pipeline = make_pipeline(RandomForestClassifier(n_estimators=150, random_state=42))\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "print(\"Random Forest Classifier\")\n",
        "print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))\n",
        "\n",
        "\n",
        "\n",
        "pipeline = make_pipeline(SMOTE(random_state=3, k_neighbors=5),\n",
        "                         RandomForestClassifier(n_estimators=150, random_state=42))\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"RF with SMOTE\")\n",
        "print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))\n",
        "\n",
        "#############################\n",
        "#UNDERSAMPLING using NearMiss\n",
        "\n",
        "pipeline = make_pipeline(NearMiss(version=1),\n",
        "                         RandomForestClassifier(n_estimators=150, random_state=42))\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "print(\"RF with near miss 1\")\n",
        "print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))\n",
        "\n",
        "#####################################\n",
        "#Easy Ensemble\n",
        "\n",
        "ee = EasyEnsembleClassifier(random_state=42)\n",
        "ee.fit(X_train, y_train)\n",
        "\n",
        "print(\"EasyEnsemble\")\n",
        "print(classification_report_imbalanced(y_test, ee.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aip5ywBwGGdA",
        "outputId": "53d85349-977f-443c-b365-c315bdff7ec2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.94      1.00      0.02      0.97      0.13      0.02      4349\n",
            "          1       0.83      0.02      1.00      0.04      0.13      0.02       277\n",
            "\n",
            "avg / total       0.93      0.94      0.08      0.91      0.13      0.02      4626\n",
            "\n",
            "RF with SMOTE\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.95      0.96      0.16      0.95      0.39      0.16      4349\n",
            "          1       0.19      0.16      0.96      0.17      0.39      0.14       277\n",
            "\n",
            "avg / total       0.90      0.91      0.20      0.91      0.39      0.16      4626\n",
            "\n",
            "RF with near miss 1\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.99      0.61      0.92      0.75      0.75      0.54      4349\n",
            "          1       0.13      0.92      0.61      0.23      0.75      0.58       277\n",
            "\n",
            "avg / total       0.94      0.62      0.91      0.72      0.75      0.54      4626\n",
            "\n",
            "EasyEnsemble\n",
            "                   pre       rec       spe        f1       geo       iba       sup\n",
            "\n",
            "          0       0.99      0.60      0.89      0.75      0.73      0.52      4349\n",
            "          1       0.12      0.89      0.60      0.22      0.73      0.55       277\n",
            "\n",
            "avg / total       0.94      0.62      0.87      0.71      0.73      0.52      4626\n",
            "\n"
          ]
        }
      ]
    }
  ]
}